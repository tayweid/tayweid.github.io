ok we've just established the idea for how a t-test works
we know the distribution of the sample mean so we can calculate the probability of seeing our sample given the null
this is a very simple version of a much more powerful model
it's more powerful but not fundamentally more complex, so do not fear
essentially all we're going to do is draw a bunch of lines on a scatterplot
they will have the form: y = mx + b
lets start with the simplest one, where there is no x (or x = 0)
this looks like a jittered plot, we have a meaningful vertical axis and we're trying to draw a line through it
let's put the line at the mean y
you'll remember that the variance is just the squared difference between the mean and each data point
so if we draw these differences, what we call residuals, and square them, we get variance
placing the line at the mean minimizes the sum of squared errors
you've already seen it with the variance and is a big idea we'll use frequenly
so if we minimize the mean squared error, we actually choose b = bar{y}, the mean wait time difference!
you'll remember that we have sampling error in every sample
so if we redraw a sample of wait time differences a couple of times we can see that the location of b is different each time
lets plot these b's on a histogram
does this look familiar? YES! it's a t-distribution
so if i were to ask you the probability of getting this sample mean under the standard null of b=0, what would you say?

ok this is nice, we have a line with no slope and we're doing a t-test
what if the data has something like a slope to it?
lets try to minimize the mean squared error
which of these three looks like it minimizes the mean squared error?
ok again, like last time, we have sampling error, now not just in the intercept, but in the slope too
here's a picture of a couple of samples
lets also plot the slopes on a histogram
does this look familiar? YEP! it's a t-distribution again
so if I were to ask you for the probability we see the data given the standard null of b_1 = 0, how would you answer?
find the p-value!

ok nice! but how do we implement this in code?


* start with an example with only a y variable and talk about the variance of the data. show a horizontal line at the mean, then show the errors as vertical lines from the mean, then show the squared errors as squares. 
* if we want to minimize the squared error we end up getting the line to sit right on the mean which also gives us the variance.
* have a slider to move around the horizontal line and a corresponding point on a graph to the right with the horizontal being the mean and the vertical being the mean squared error
* so minimizing the squared error term is equivalent to finding the mean
* then run a bunch of samples showing that the mean follows a normal distribution around the truth and show it as a histogram
* so this not only gives us the mean of the sample but it also gives us a way of quantifying our level of confidence about where the true mean is
* we know the distribution of the sample means so we can calculate the probability that the mean is as extreme as zero, which is the p-value for our default null
* this tells us the probability that the we would see an event this extreme under the null
* we interpret this as being a "statistically significant coefficient", meaning we're very confident it's not zero. out best guess in this case is that it's the parameter estimate.
* nice, this is our t-test but done in a slightly different way. we get the same numbers if we run this using a regression or a t-test.
* then go back to the scatterplot but with a relationship between the x and y
* this one is different. we could run a horizontal line through it but that would essentially assume that small and large x are the same, like last time.
* what if we want to use this idea of a t-test to test whether there is a relationship? 
* well lets allow the line to have a slope: y=b_0 + b_1x + e and minimize the squared error
* like before we move the parameters around and we get a line that looks like this
* lets do this a bunch of times and plot the b_1 coefficients
* see it's again a t-distribution!
* this means we can find the probability of being as far away as b_1 from 0. this is our p-value.
* this is the general linear model. we sometimes call it regression. it's a more flexible version of the t-test and is how we do nearly everything empirical in every field of science. 
