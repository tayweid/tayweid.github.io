---
format:
  revealjs:
    css: custom.css
    transition: none
    aspect-ratio: "16:9"
---

## ECON 0150 | Economic Data Analysis {.center}
<p class="subheader-center">The economist's data analysis skillset.</p>

<br> 

### *Part 3.2 | Sampling and the Central Limit Theorem*

---

## A Big Question
<p class="subheader">If all we see is the sample, how do we learn about a population?</p>

<br><br>

. . .

- In general, a population's random variables will be unobservable.

. . .

- If we only see a sample, what *can *we say about the population?

---

## Random Variables: Known
<p class="subheader">If we know the random variable, we can learn many things about the population.</p>

:::: {.columns}
::: {.column width="40%"}
- Probability wait time < 10:
  - P(X < 10) = 0.21
- Probability wait time > 15:
  - P(X > 15) = 0.11
- Probability between 10 - 15:
  - P(10 < X < 15) = 0.59
:::

::: {.column width="60%"}
![](i/c_01.png)
:::
::::

. . .

<br>

*> when we know the probability function, we can calculate everything exactly*

---

## Random Variables: Known
<p class="subheader">If we know the random variable, we can learn many things about the population.</p>

![](i/distributions.png)

. . .

*> but what can we know about the population if we only see the sample?*

---

## Random Variables: Unknown
<p class="subheader">But if all we see is the sample, what can we know about a population?</p>

![](i/sample.png)

. . .

*> how do we learn about $\mu$ if all we have is $n$, $\bar{x}$, and $S$?*

---

## Exercise 3.2 | Sampling Dice (sample size: n=1)
<p class="subheader">Lets pretend we don't know the probability function for dice.</p>

<br>

Lets start with something boring.

<br>

1. Roll a dice once (sample size: n=1).
2. We'll plot the distribution of our samples.

---

## Exercise 3.2 | Sampling Variability
<p class="subheader">Your samples have a lot of variability!</p>

![](i/c_02.png)

. . .

*> this variability perfectly matches what we would expect from a fair dice*

---

## Exercise 3.2 | Sampling Dice (n=2)
<p class="subheader">Lets pretend we don't know the probability function for dice.</p>

<br>

Next is something slighly less boring.

<br>

1. Roll a dice once (sample size: n=2).
2. We'll plot the distribution of our samples.

---

## Exercise 3.2 | Sampling Variability
<p class="subheader">Like before, each sample has a slighly different sample mean.</p>

![](i/c_03.png)

<br> 

. . .

*> theres a lot of variability in your sample means!*

. . .

*> what do you expect to see when we plot these sample means ($\bar{x}$)?*

---

## Exercise 3.2 | Sampling Variability
<p class="subheader">The variability in the sample mean with a larger sample size.</p>

![](i/c_04.png)

. . .

<br>

*> our sample means are more bunched (like a pyramid) in the middle! why?*

. . .

*> there are more ways to get 7/2 than 2/2!*


---

## Exercise 3.2 | Sampling Dice (n=3)
<p class="subheader">Lets pretend we don't know the probability function for dice.</p>

<br>

Next is something even less boring.

<br>

1. Roll a dice once (sample size: n=3).
2. We'll plot the distribution of our samples.

---

## Exercise 3.2 | Sampling Variability
<p class="subheader">The variability in the sample mean with a larger sample size.</p>

![](i/c_05.png)

. . .

*> theres a even more variability in your sample means!*

. . .

*> what do you expect to see when we plot these sample means ($\bar{x}$)?*

---

## Exercise 3.2 | Sampling Variability
<p class="subheader">The variability in the sample mean with a larger sample size.</p>

![](i/c_06.png)

*> what do you notice with the shape with n=3?*

---

## Exercise 3.2 | Sampling Variability
<p class="subheader">The variability in the sample mean with a larger sample size.</p>

![](i/c_07.png)

*> what do you notice with the shape with n=3?*

---

## Exercise 3.2 | Sampling Variability
<p class="subheader">The variability in the sample mean with a larger sample size.</p>

![](i/c_07.png)

*> there's some curvature to the shape*

---

## Exercise 3.2 | Sampling Dice (n=30)
<p class="subheader">Lets pretend we don't know the probability function for dice.</p>

<br>

Next is something very un-boring.

<br>

1. Roll a dice once (sample size: n=30).
2. We'll plot the distribution of our samples.

---

## Exercise 3.2 | Sampling Variability
<p class="subheader">The variability in the sample mean with a larger sample size.</p>

![](i/c_08.png)

. . .

*> theres a even more ways your sample could look!*

. . .

*> what do you expect to see when we plot these sample means ($\bar{x}$)?*

---

## Exercise 3.2 | Sampling Variability
<p class="subheader">What happens when we really increase the sample size?</p>

![](i/c_09.png)

*> what do you notice with the shape with n=30?*

---

## Exercise 3.2 | Sampling Variability
<p class="subheader">What happens when we really increase the sample size?</p>

![](i/c_09.png)

*> the distribution of sample means gets tighter and more bell-shaped*

---

## Exercise 3.2 | Sampling Variability
<p class="subheader">What happens when we really increase the sample size?</p>

![](i/c_10.png)

. . .

*> what is this probability function in red?*

---

## Random Variables: Known
<p class="subheader">If we know the random variable, we can learn many things about the population.</p>

:::: {.columns}
::: {.column width="40%"}
- Probability wait time < 10:
  - P(X < 10) = 0.21
- Probability wait time > 15:
  - P(X > 15) = 0.11
- Probability between 10 - 15:
  - P(10 < X < 15) = 0.59
:::

::: {.column width="60%"}
![](i/c_01.png)
:::
::::

<br>

*> when we know the probability function, we can calculate everything exactly*

---

## Random Variables: Unknown
<p class="subheader">If we take multiple samples, we get different sample means.</p>

Each sample gives us a different estimate of the population mean.

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import seaborn as sns


np.random.seed(123)
n_samples = 5
sample_size = 30
samples = [np.random.normal(12, 2.5, sample_size) for _ in range(n_samples)]
means = [np.mean(s) for s in samples]

plt.figure(figsize=(9, 3))
for i, s in enumerate(samples):
    plt.subplot(1, n_samples, i+1)
    plt.hist(s, bins=8, alpha=0.7)
    plt.axvline(x=means[i], color='red', linestyle='--')
    plt.title(f'xÌ„ = {means[i]:.1f}')
    plt.yticks([])
    plt.xticks([6, 12, 18])
  
    plt.xlabel('Minutes', fontsize=16)
sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)

plt.tight_layout()
plt.show()
```

---

## Random Variables: Unknown
<p class="subheader">If we take multiple samples, their means will vary.</p>

<br><br>

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats


np.random.seed(123)
n_samples = 500
sample_size = 30
samples = [np.random.normal(12, 2.5, sample_size) for _ in range(n_samples)]
means = [np.mean(s) for s in samples]

plt.figure(figsize=(9, 3))
plt.hist(means, bins=20, alpha=0.7, label='Sample means (n=30)', density=True)
plt.yticks([])
plt.xticks([6, 12, 18])
plt.xlabel('Minutes', fontsize=16)
plt.xlim(6,18)
plt.legend()

sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)

plt.tight_layout()
plt.show()
```

---

## Random Variables: Unknown
<p class="subheader">If we take multiple samples, their means will vary, and by much less than the original distribution.</p>

<br><br>

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats


np.random.seed(123)
n_samples = 500
sample_size = 30
samples = [np.random.normal(12, 2.5, sample_size) for _ in range(n_samples)]
means = [np.mean(s) for s in samples]
all_samples = np.random.normal(12, 2.5, 30000)

plt.figure(figsize=(9, 3))
plt.hist(means, bins=20, alpha=0.7, label='Sample means (n=30)', density=True)
plt.hist(all_samples, bins=40, alpha=0.3, label='Sample observations', zorder=-1, density=True)
plt.yticks([])
plt.xticks([6, 12, 18])
plt.xlabel('Minutes', fontsize=16)
plt.xlim(6,18)
plt.legend()

sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)

plt.tight_layout()
plt.show()
```

*> why? think about rolling two dice... it's much less likely to get a 2 than a 7*

---

## Random Variables: Unknown
<p class="subheader">As sample size grows, the distribution of the sample means approaches a normal distribution.</p>

<br><br>

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats


np.random.seed(123)
n_samples = 500
sample_size = 30
samples = [np.random.normal(12, 2.5, sample_size) for _ in range(n_samples)]
means = [np.mean(s) for s in samples]

plt.figure(figsize=(9, 3))
plt.hist(means, bins=20, alpha=0.7, label='Sample means (n=30)', density=True)
plt.hist(all_samples, bins=40, alpha=0.1, label='Sample observations', zorder=-1, density=True)

x = np.linspace(10, 14, 1000)
y = stats.norm.pdf(x, 12, 2.5/np.sqrt(sample_size))
plt.plot(x, y, 'r-', label='Normal Distribution')

plt.yticks([])
plt.xticks([6, 12, 18])
plt.xlabel('Minutes', fontsize=16)
plt.xlim(6,18)
plt.legend()

sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)

plt.tight_layout()
plt.show()
```

---

## Random Variables: Unknown
<p class="subheader">As sample size grows, the normal distribution the sample means approach gets narrower.</p>

<br><br>

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats


np.random.seed(123)
n_samples = 500
sample_size = 30
samples = [np.random.normal(12, 2.5, sample_size) for _ in range(n_samples)]
means = [np.mean(s) for s in samples]

plt.figure(figsize=(9, 3))
plt.hist(means, bins=20, alpha=0.7, label='Sample means (n=30)', density=True)
plt.hist(all_samples, bins=40, alpha=0.1, label='Sample means (n=1)', zorder=-1, density=True)

n_samples = 500
sample_size = 60
samples = [np.random.normal(12, 2.5, sample_size) for _ in range(n_samples)]
means = [np.mean(s) for s in samples]
plt.hist(means, bins=20, alpha=0.7, label='Sample means (n=60)', density=True)

x = np.linspace(10, 14, 1000)
y = stats.norm.pdf(x, 12, 2.5/np.sqrt(sample_size))
plt.plot(x, y, 'r-', label='Normal Distribution')

plt.yticks([])
plt.xticks([6, 12, 18])
plt.xlabel('Minutes', fontsize=16)
plt.xlim(6,18)
plt.legend()

sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)

plt.tight_layout()
plt.show()
```

---

## Random Variables: Unknown
<p class="subheader">The normal distribution the sample means approach is centered on the population mean!</p>

<br><br>

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(123)
n_samples = 500
sample_size = 30
samples = [np.random.normal(12, 2.5, sample_size) for _ in range(n_samples)]
means = [np.mean(s) for s in samples]

plt.figure(figsize=(9, 3))
plt.hist(means, bins=20, alpha=0.7, label='Sample means (n=30)', density=True)
plt.hist(all_samples, bins=40, alpha=0.1, label='Sample means (n=1)', zorder=-1, density=True)

n_samples = 500
sample_size = 60
samples = [np.random.normal(12, 2.5, sample_size) for _ in range(n_samples)]
means = [np.mean(s) for s in samples]
plt.hist(means, bins=20, alpha=0.7, label='Sample means (n=60)', density=True)

n_samples = 500
sample_size = 1000
samples = [np.random.normal(12, 2.5, sample_size) for _ in range(n_samples)]
means = [np.mean(s) for s in samples]
plt.hist(means, bins=20, alpha=0.7, label='Sample means (n=1000)', density=True)

x = np.linspace(10, 14, 1000)
y = stats.norm.pdf(x, 12, 2.5/np.sqrt(sample_size))
plt.plot(x, y, 'r-', label='Normal Distribution')

plt.yticks([])
plt.xticks([6, 12, 18])
plt.xlabel('Minutes', fontsize=16)
plt.xlim(6,18)
plt.legend()

sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)

plt.tight_layout()
plt.show()
```

. . .

*> the sample mean $\bar{x}$ follows a normal distribution around the truth* ðŸ˜±

$$\bar{x} \sim N\Big(\mu, \frac{\sigma}{\sqrt{n}}\Big)$$

---

## Random Variables: Unknown
<p class="subheader">This works for (nearly) any distribution shape as sample size increases.</p>
```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import seaborn as sns

# Create a skewed distribution
def skewed_dist(size):
    return stats.chi2.rvs(df=3, size=size)

sample_sizes = [1, 5, 30, 1000]
n_samples = 10000
fig, axes = plt.subplots(4, 1, figsize=(10, 6))

# Different sample sizes
for i, n in enumerate(sample_sizes):
    sample_means = []
    for _ in range(n_samples):
        sample = skewed_dist(n)
        sample_means.append(np.mean(sample))
    
    bin_size = 30
    edge_color='white'
    if n > 100:
      bin_size = 60
      edge_color = '#4C72B0'

    axes[i].hist(sample_means, bins=bin_size, density=True, alpha=0.7,
                  edgecolor=edge_color, color='#4C72B0', label=f'Sample Mean (n={n})')
    axes[i].set_xlabel("")
    axes[i].set_xlim(0, 15)
    axes[i].set_yticks([])
    axes[i].legend()
    
    # Add a normal curve for larger sample sizes
    if n >= 5:
        x = np.linspace(min(sample_means), max(sample_means), 100)
        mean_est = 3  # Chi-square df=3 has mean of 3
        std_est = np.sqrt(6/n)  # Chi-square df=3 has variance of 6
        y = stats.norm.pdf(x, mean_est, std_est)
        axes[i].plot(x, y, 'r--', linewidth=2)

sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)
plt.tight_layout()
plt.show()
```

---

## The Central Limit Theorem
<p class="subheader">The distribution of sample means approximates a normal distribution as sample size increases, regardless of the population's distribution.</p>

:::: {.columns}
::: {.column width="50%"}
#### Key insights:

  - Sample means cluster around Î¼
  - Standard error = Ïƒ/âˆšn
  - Normal shape emerges

#### Implications:

  - We can predict the behavior of xÌ„
  - This works for (nearly) ANY distribution
:::

::: {.column width="50%"}
```{python}
#| echo: false
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

np.random.seed(123)
n_means = 1000
sample_size = 30
sample_means = [np.mean(np.random.normal(12, 2.5, sample_size)) 
                for _ in range(n_means)]

plt.figure(figsize=(5, 3))
plt.hist(sample_means, bins=25, density=True, alpha=0.5)
x = np.linspace(10, 14, 1000)
y = stats.norm.pdf(x, 12, 2.5/np.sqrt(sample_size))
plt.plot(x, y, 'r-')
plt.axvline(x=12, color='blue', linestyle='--')
plt.title(f'Distribution of Sample Means (n={sample_size})')
plt.yticks([])

sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)

plt.tight_layout()
plt.show()
```
:::
::::
