---
format:
  revealjs:
    css: custom.css
    transition: none
    aspect-ratio: "16:9"
---

## ECON 0150 | Economic Data Analysis {.center}
<p class="subheader-center">The economist's data analysis skillset.</p>

<br> 

### *Part 3.4 | Testing*

---

## A Big Question
<p class="subheader">How do we learn about the population when we don't know $\mu$ or $\sigma$?</p>

<br><br>

:::{.incremental}
- Last time: t-distribution accounts for uncertainty in both $\bar{x}$ and $s$
- The distance between $\bar{x}$ and $\mu$ is symmetric
- Today: flip our perspective and build statistical models
:::

---

## Sampling Distribution: Unknown $\mu$; Known $\sigma$
<p class="subheader">If we know the population mean, we know the sampling distribution is approximately normal.</p>

The sample mean is drawn from an approximately normal distribution with mean $\mu$ and standard error $\sigma / \sqrt{n}$.

Each time we draw a sample we see a different sample mean.

What do we do that we don't observe $\mu$? We measure 'closeness'.

---

## Unknown $\mu$: Two Perspectives
<p class="subheader">There are two mathematically equivalent perspectives to think about "closeness" between $\mu$ and $\bar{x}$.</p>

. . .

Perspective 1: probability $\bar{x}$ is close to $\mu$

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import seaborn as sns

# Setup
x = np.linspace(8, 16, 1000)
mu = 12
sigma = 2.5
n = 30
se = sigma/np.sqrt(n)
sample_mean = 11.6  # Example sample mean

fig, ax1 = plt.subplots(1, 1, figsize=(9, 2))

# First plot: x̄ around μ
y1 = stats.norm.pdf(x, mu, se)
ax1.plot(x, y1, 'b-', alpha=0.5)
ax1.axvline(x=mu, color='green', linestyle='--', label='$\mu$')
ax1.axvline(x=sample_mean, color='red', linestyle='--', label='$\\bar{x}$')
ax1.fill_between(x[(x >= mu-se) & (x <= mu+se)], 
                 y1[(x >= mu-se) & (x <= mu+se)], 
                 color='blue', alpha=0.3)
ax1.set_title('Confidence Interval centered on $\mu$')
ax1.set_yticks([])
ax1.legend()

sns.despine(left=True, bottom=False, right=True, top=True, offset=-4, trim=True)
plt.tight_layout()
plt.show()
```

. . .

Perspective 2: probability $\mu$ is close to $\bar{x}$


```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Setup
x = np.linspace(8, 16, 1000)
mu = 12
sigma = 2.5
n = 30
se = sigma/np.sqrt(n)

fig, ax2 = plt.subplots(1, 1, figsize=(9, 2))

# Second plot: μ around x̄
sample_mean = 11.6  # Example sample mean
y2 = stats.norm.pdf(x, sample_mean, se)
ax2.plot(x, y2, 'b-', alpha=0.5)
ax2.axvline(x=mu, color='green', linestyle='--', label='$\mu$')
ax2.axvline(x=sample_mean, color='red', linestyle='--', label='$\\bar{x}$')
ax2.fill_between(x[(x >= sample_mean-se) & (x <= sample_mean+se)], 
                 y2[(x >= sample_mean-se) & (x <= sample_mean+se)], 
                 color='blue', alpha=0.3)
ax2.set_title('Confidence Interval centered on $\\bar{x}$')
ax2.set_yticks([])
ax2.legend()

sns.despine(left=True, bottom=False, right=True, top=True, offset=-4, trim=True)
plt.tight_layout()
plt.show()
```

---

## Difference Center Points
<p class="subheader">There are two mathematically equivalent perspectives to think about "closeness" between $\mu$ and $\bar{x}$.</p>

I repeated sampled a distribution and constructed a 95% confidence interval.

![](i/Confidence_Intervals_Around_Mean.png){fig-align="center"}

. . .

*> it is mathematically equivalent to check whether $\mu$ is in the CI around $\bar{x}$!*


---

## Flipping the Perspective
<p class="subheader">The distance between $\bar{x}$ and $\mu$ works both ways.</p>

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import seaborn as sns

# Update Matplotlib parameters
plt.rcParams.update({
    'font.family': 'serif',
    'font.serif': ['Times New Roman'],
    'font.style': 'italic',
})

np.random.seed(42)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 3))

# Left panel: centered on mu
mu = 12
sigma = 2.5
n = 30
se = sigma/np.sqrt(n)

x = np.linspace(10, 14, 1000)
y = stats.norm.pdf(x, mu, se)

ax1.plot(x, y, 'b-', linewidth=2)
ax1.axvline(x=mu, color='red', linestyle='--', linewidth=2, label='μ (unknown)')
ax1.fill_between(x, y, alpha=0.3)
ax1.set_xlabel('Sample Mean', fontsize=14)
ax1.set_title('Centered on Unknown μ', fontsize=14)
ax1.set_yticks([])
ax1.text(mu, max(y)*0.5, 'Where will $\\bar{x}$ fall?', ha='center')

# Right panel: centered on x_bar
x_bar = 11.5
x = np.linspace(9.5, 13.5, 1000) 
y = stats.norm.pdf(x, x_bar, se)

ax2.plot(x, y, 'g-', linewidth=2)
ax2.axvline(x=x_bar, color='green', linestyle='--', linewidth=2, label='x̄ (observed)')
ax2.fill_between(x, y, alpha=0.3, color='green')
ax2.set_xlabel('Population Mean', fontsize=14)
ax2.set_title('Centered on Observed x̄', fontsize=14)
ax2.set_yticks([])
ax2.text(x_bar, max(y)*0.5, 'Where could μ be?', ha='center')

sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)
plt.tight_layout()
plt.show()
```

. . .

*> same distribution shape, just different reference points*

---

## Wait Times: Multiple Samples
<p class="subheader">Each sample gives us a different $\bar{x}$ and $s$.</p>

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import seaborn as sns

np.random.seed(123)
fig, axes = plt.subplots(1, 5, figsize=(14, 4))

mu = 12
sigma = 2.5
n = 30

for i in range(5):
    sample = np.random.normal(mu, sigma, n)
    x_bar = np.mean(sample)
    s = np.std(sample, ddof=1)
    
    # Strip plot
    axes[i].scatter(np.ones(n)*0.5, sample, alpha=0.6, s=30)
    axes[i].axhline(y=x_bar, color='red', linestyle='-', linewidth=2)
    axes[i].set_xlim(0, 1)
    axes[i].set_ylim(5, 19)
    axes[i].set_xticks([])
    axes[i].set_title(f'x̄={x_bar:.1f}\ns={s:.1f}', fontsize=12)
    if i == 0:
        axes[i].set_ylabel('Wait Time (minutes)', fontsize=12)
    
    # Add true mean as reference
    axes[i].axhline(y=mu, color='blue', linestyle='--', alpha=0.3)

sns.despine(left=False, bottom=True, right=True, top=True, offset=0, trim=True)
plt.suptitle('Five Different Samples (n=30 each)', fontsize=14, y=1.02)
plt.tight_layout()
plt.show()
```

. . .

*> notice both $\bar{x}$ (red lines) and $s$ vary across samples*

---

## Centering on $\bar{x}$
<p class="subheader">Instead of asking where $\bar{x}$ falls around $\mu$, we ask where $\mu$ could be around $\bar{x}$.</p>

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import seaborn as sns

np.random.seed(123)
fig, axes = plt.subplots(2, 3, figsize=(14, 6))

mu = 12
sigma = 2.5
n = 30

# Generate three samples
samples = []
for i in range(3):
    sample = np.random.normal(mu, sigma, n)
    samples.append(sample)

# Top row: samples with their means
for i in range(3):
    sample = samples[i]
    x_bar = np.mean(sample)
    s = np.std(sample, ddof=1)
    se = s/np.sqrt(n)
    
    # Strip plot
    axes[0, i].scatter(np.ones(n)*0.5, sample, alpha=0.6, s=30)
    axes[0, i].axhline(y=x_bar, color='red', linestyle='-', linewidth=2)
    axes[0, i].set_xlim(0, 1)
    axes[0, i].set_ylim(5, 19)
    axes[0, i].set_xticks([])
    axes[0, i].set_title(f'Sample {i+1}: x̄={x_bar:.1f}', fontsize=12)
    if i == 0:
        axes[0, i].set_ylabel('Wait Time', fontsize=12)

# Bottom row: sampling distributions centered on x_bar
for i in range(3):
    x_bar = np.mean(samples[i])
    s = np.std(samples[i], ddof=1)
    se = s/np.sqrt(n)
    
    x = np.linspace(10, 14, 1000)
    y = stats.t.pdf(x, df=n-1, loc=x_bar, scale=se)
    
    axes[1, i].plot(x, y, 'g-', linewidth=2)
    axes[1, i].axvline(x=x_bar, color='red', linestyle='-', linewidth=2)
    axes[1, i].axvline(x=mu, color='blue', linestyle='--', alpha=0.5)
    
    # Shade 95% CI
    t_crit = stats.t.ppf(0.975, df=n-1)
    ci_lower = x_bar - t_crit * se
    ci_upper = x_bar + t_crit * se
    axes[1, i].fill_between(x[(x >= ci_lower) & (x <= ci_upper)], 
                            y[(x >= ci_lower) & (x <= ci_upper)], 
                            alpha=0.3, color='green')
    
    axes[1, i].set_xlim(10, 14)
    axes[1, i].set_yticks([])
    if i == 0:
        axes[1, i].set_ylabel('Density', fontsize=12)
    axes[1, i].set_xlabel('Possible μ values', fontsize=12)

sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)
plt.tight_layout()
plt.show()
```

. . .

*> each sample creates its own confidence interval for where μ could be*

---

## The Sample Standard Deviation Varies
<p class="subheader">Just like $\bar{x}$ varies around $\mu$, the sample SD varies around $\sigma$.</p>

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import seaborn as sns

np.random.seed(42)
n_samples = 1000
n = 30
sigma = 2.5

sample_sds = []
for _ in range(n_samples):
    sample = np.random.normal(12, sigma, n)
    sample_sds.append(np.std(sample, ddof=1))

plt.figure(figsize=(10, 3))
plt.hist(sample_sds, bins=30, density=True, alpha=0.7, color='orange')
plt.axvline(x=sigma, color='blue', linestyle='--', linewidth=2, label=f'True σ = {sigma}')
plt.axvline(x=np.mean(sample_sds), color='red', linestyle='-', linewidth=2, 
            label=f'Mean of s = {np.mean(sample_sds):.2f}')
plt.xlabel('Sample Standard Deviation', fontsize=14)
plt.ylabel('Density', fontsize=14)
plt.title(f'Distribution of Sample SD (n={n}, 1000 samples)', fontsize=14)
plt.legend()
plt.yticks([])

sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)
plt.tight_layout()
plt.show()
```

. . .

*> this variability in $s$ is why we need the t-distribution*

---

## What Happens If We Ignore This?
<p class="subheader">Using the normal distribution with $s$ gives wrong coverage rates.</p>

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import seaborn as sns

np.random.seed(42)
n_simulations = 1000
n = 30
mu = 12
sigma = 2.5
confidence_level = 0.95

# Track coverage
normal_coverage = []
t_coverage = []

for _ in range(n_simulations):
    sample = np.random.normal(mu, sigma, n)
    x_bar = np.mean(sample)
    s = np.std(sample, ddof=1)
    se = s / np.sqrt(n)
    
    # Normal CI (incorrect)
    z_crit = stats.norm.ppf((1 + confidence_level) / 2)
    normal_ci_lower = x_bar - z_crit * se
    normal_ci_upper = x_bar + z_crit * se
    normal_coverage.append(normal_ci_lower <= mu <= normal_ci_upper)
    
    # t CI (correct)
    t_crit = stats.t.ppf((1 + confidence_level) / 2, df=n-1)
    t_ci_lower = x_bar - t_crit * se
    t_ci_upper = x_bar + t_crit * se
    t_coverage.append(t_ci_lower <= mu <= t_ci_upper)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

# Plot coverage rates
categories = ['Normal\n(incorrect)', 't-distribution\n(correct)']
coverage_rates = [np.mean(normal_coverage), np.mean(t_coverage)]
colors = ['red', 'green']

bars = ax1.bar(categories, coverage_rates, color=colors, alpha=0.7)
ax1.axhline(y=0.95, color='blue', linestyle='--', label='Target: 95%')
ax1.set_ylabel('Coverage Rate', fontsize=14)
ax1.set_title('Actual Coverage of 95% Confidence Intervals', fontsize=14)
ax1.set_ylim(0.9, 1.0)
ax1.legend()

# Add text labels
for bar, rate in zip(bars, coverage_rates):
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,
             f'{rate:.1%}', ha='center', va='bottom', fontsize=12)

# Show distribution comparison
x = np.linspace(-3, 3, 1000)
ax2.plot(x, stats.norm.pdf(x), 'r-', label='Normal', alpha=0.7)
ax2.plot(x, stats.t.pdf(x, df=n-1), 'g-', label=f't (df={n-1})', alpha=0.7)
ax2.set_xlabel('Standard Errors from Mean', fontsize=14)
ax2.set_ylabel('Density', fontsize=14)
ax2.set_title('Why t-distribution?', fontsize=14)
ax2.legend()

sns.despine(left=False, bottom=False, right=True, top=True, offset=0, trim=True)
plt.tight_layout()
plt.show()
```

. . .

*> using normal with $s$ only captures the truth ~93% of the time instead of 95%*

---

## Exercise 3.4 | Coverage Simulation
<p class="subheader">Let's verify the coverage rates ourselves.</p>

Generate many samples and check if the CI contains the true mean:

```{python}
#| echo: true
#| eval: false
# Simulation parameters
n_samples = 1000
sample_size = 30
true_mu = 12
true_sigma = 2.5

# Count how many CIs contain the truth
contains_truth = 0

for i in range(n_samples):
    sample = np.random.normal(true_mu, true_sigma, sample_size)
    x_bar = np.mean(sample)
    s = np.std(sample, ddof=1)
    se = s / np.sqrt(sample_size)
    
    # 95% CI using t-distribution
    t_crit = stats.t.ppf(0.975, df=sample_size-1)
    ci_lower = x_bar - t_crit * se
    ci_upper = x_bar + t_crit * se
    
    if ci_lower <= true_mu <= ci_upper:
        contains_truth += 1

print(f"Coverage: {contains_truth/n_samples:.1%}")
```

. . .

*> should be very close to 95%*

---

## Building a Statistical Model
<p class="subheader">Now let's use this framework to build our first model.</p>

. . .

The simplest possible model: $E[y] = \beta_0$

. . .

- This is just a horizontal line through the data
- The line that minimizes squared errors passes through $\bar{y}$
- We want to test if this line could be at zero: $H_0: \beta_0 = 0$

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

np.random.seed(42)
n = 30
y = np.random.normal(2, 2.5, n)
y_bar = np.mean(y)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

# Left: data with horizontal line
ax1.scatter(range(n), y, alpha=0.6)
ax1.axhline(y=y_bar, color='red', linewidth=2, label=f'ȳ = {y_bar:.2f}')
ax1.axhline(y=0, color='blue', linestyle='--', alpha=0.5, label='H₀: β₀ = 0')
ax1.set_xlabel('Observation', fontsize=14)
ax1.set_ylabel('y', fontsize=14)
ax1.set_title('Simplest Model: E[y] = β₀', fontsize=14)
ax1.legend()

# Right: sampling distribution
s = np.std(y, ddof=1)
se = s / np.sqrt(n)
x = np.linspace(-2, 6, 1000)
y_dist = stats.t.pdf(x, df=n-1, loc=y_bar, scale=se)

ax2.plot(x, y_dist, 'g-', linewidth=2)
ax2.axvline(x=y_bar, color='red', linewidth=2, label='ȳ')
ax2.axvline(x=0, color='blue', linestyle='--', linewidth=2, label='H₀: β₀ = 0')
ax2.fill_between(x[x >= y_bar], y_dist[x >= y_bar], alpha=0.3, color='red')
ax2.fill_between(x[x <= -y_bar], y_dist[x <= -y_bar], alpha=0.3, color='red')
ax2.set_xlabel('Possible β₀ values', fontsize=14)
ax2.set_yticks([])
ax2.set_title('Testing H₀: β₀ = 0', fontsize=14)
ax2.legend()

sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)
plt.tight_layout()
plt.show()
```

---

## The t-test for Our Model
<p class="subheader">Testing whether $\beta_0 = 0$ is just a t-test!</p>

```{python}
#| echo: true
# Our data
y = np.random.normal(2, 2.5, 30)
y_bar = np.mean(y)
s = np.std(y, ddof=1)
n = len(y)
se = s / np.sqrt(n)

# t-statistic for H0: beta_0 = 0
t_stat = (y_bar - 0) / se
p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=n-1))

print(f"Model: E[y] = {y_bar:.2f}")
print(f"t-statistic: {t_stat:.2f}")
print(f"p-value: {p_value:.4f}")
```

. . .

*> if p < 0.05, we reject the hypothesis that the mean is zero*

---

## Testing Different Hypotheses
<p class="subheader">What if we want to test $H_0: \beta_0 = 2$ instead of 0?</p>

. . .

Clever trick: shift all the data and test against zero!

```{python}
#| echo: true
# Test H0: beta_0 = 2
null_value = 2
y_shifted = y - null_value  # Shift the data

# Now test if shifted mean equals zero
y_bar_shifted = np.mean(y_shifted)
t_stat = y_bar_shifted / (s / np.sqrt(n))
p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=n-1))

print(f"Testing H0: β₀ = {null_value}")
print(f"t-statistic: {t_stat:.2f}")
print(f"p-value: {p_value:.4f}")
```

. . .

*> this works for any hypothesized value*

---

## Exercise 3.4 | Testing Multiple Hypotheses
<p class="subheader">Let's test several different null hypotheses for the same data.</p>

```{python}
#| echo: false
#| fig-align: center
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import seaborn as sns

np.random.seed(42)
y = np.random.normal(2, 2.5, 30)
y_bar = np.mean(y)
s = np.std(y, ddof=1)
n = len(y)
se = s / np.sqrt(n)

# Test different null values
null_values = np.linspace(-2, 6, 100)
p_values = []

for null in null_values:
    t_stat = (y_bar - null) / se
    p_val = 2 * (1 - stats.t.cdf(abs(t_stat), df=n-1))
    p_values.append(p_val)

plt.figure(figsize=(10, 4))
plt.plot(null_values, p_values, 'b-', linewidth=2)
plt.axhline(y=0.05, color='red', linestyle='--', label='α = 0.05')
plt.axvline(x=y_bar, color='green', linestyle='--', label=f'ȳ = {y_bar:.2f}')
plt.fill_between(null_values, 0, p_values, where=(np.array(p_values) > 0.05), 
                  alpha=0.3, color='blue', label='95% CI')
plt.xlabel('Null Hypothesis Value (β₀)', fontsize=14)
plt.ylabel('p-value', fontsize=14)
plt.title('p-values for Different Null Hypotheses', fontsize=14)
plt.ylim(0, 1)
plt.legend()

sns.despine(left=False, bottom=False, right=True, top=True, offset=0, trim=True)
plt.tight_layout()
plt.show()
```

. . .

*> the values where p > 0.05 form our 95% confidence interval!*

---

## Connection to Confidence Intervals
<p class="subheader">Testing hypotheses and confidence intervals are two sides of the same coin.</p>

. . .

- **Confidence Interval**: All values of $\beta_0$ we wouldn't reject at α = 0.05

. . .

- **Hypothesis Test**: Is a specific $\beta_0$ in the confidence interval?

. . .

- They use the exact same t-distribution framework

. . .

*> this is why both are based on the t-distribution with n-1 degrees of freedom*

---

## Looking Forward: Regression
<p class="subheader">This framework extends directly to regression analysis.</p>

. . .

**Today's model**: $E[y] = \beta_0$ (just an intercept)

. . .

**Next:** $E[y] = \beta_0 + \beta_1 x$ (intercept and slope)

. . .

- Each $\beta$ coefficient will have its own t-test
- Same framework: estimate ± t-critical × SE
- The t-distribution accounts for uncertainty in our estimates

. . .

*> regression is just an extension of what we learned today*

---

## Summary
<p class="subheader">We've built the foundation for statistical modeling.</p>

<br>

:::{.incremental}
- Flipped perspective: center on what we observe ($\bar{x}$) not what's unknown ($\mu$)
- Sample SD varies, creating need for t-distribution
- Built our first model: $E[y] = \beta_0$
- Tested hypotheses by shifting data
- Connected hypothesis tests to confidence intervals
:::

. . .

<br>

*> these tools form the foundation of econometric analysis*