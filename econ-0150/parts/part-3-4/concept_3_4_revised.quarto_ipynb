{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "format:\n",
        "  revealjs:\n",
        "    css: custom.css\n",
        "    transition: none\n",
        "    aspect-ratio: \"16:9\"\n",
        "---\n",
        "\n",
        "\n",
        "## ECON 0150 | Economic Data Analysis {.center}\n",
        "<p class=\"subheader-center\">The economist's data analysis skillset.</p>\n",
        "\n",
        "<br> \n",
        "\n",
        "### *Part 3.4 | Hypothesis Testing*\n",
        "\n",
        "---\n",
        "\n",
        "## A Big Question\n",
        "<p class=\"subheader\">How do we learn about the population when we don't know $\\mu$ or $\\sigma$?</p>\n",
        "\n",
        "<br>\n",
        "\n",
        ":::{.incremental}\n",
        "- **Part 3.1** | Known Random Variables\n",
        "    - If we know the random variable, we can answer all kinds of probability questions\n",
        "- **Part 3.2** | Sampling and Unknown Random Variables\n",
        "    - The sample means of unknown random variables will approximate a normal distribution around the truth\n",
        "- **Part 3.3** | Confidence Intervals\n",
        "    - We can use the sampling distribution to know the probability that the sample mean ($\\bar{x}$) will be close to the population mean ($\\mu$)\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Sampling Distribution: Unknown $\\mu$; Known $\\sigma$\n",
        "<p class=\"subheader\">If we know the population mean, we know the sampling distribution is approximately normal.</p>\n",
        "\n",
        "<br><br>\n",
        "\n",
        ":::{.incremental}\n",
        "- The sample mean is drawn from an approximately normal distribution with mean $\\mu$ and standard error $\\sigma / \\sqrt{n}$.\n",
        "- Each time we draw a sample we see a different sample mean.\n",
        "- What do we do that we don't observe $\\mu$? We measure 'closeness'.\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Unknown $\\mu$: Two Perspectives\n",
        "<p class=\"subheader\">There are two mathematically equivalent perspectives to think about \"closeness\" between $\\mu$ and $\\bar{x}$.</p>\n",
        "\n",
        ". . .\n",
        "\n",
        "Perspective 1: probability $\\bar{x}$ is close to $\\mu$\n"
      ],
      "id": "c9948b47"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "# Setup\n",
        "x = np.linspace(8, 16, 1000)\n",
        "mu = 12\n",
        "sigma = 2.5\n",
        "n = 30\n",
        "se = sigma/np.sqrt(n)\n",
        "sample_mean = 11.6  # Example sample mean\n",
        "\n",
        "fig, ax1 = plt.subplots(1, 1, figsize=(9, 2))\n",
        "\n",
        "# First plot: x̄ around μ\n",
        "y1 = stats.norm.pdf(x, mu, se)\n",
        "ax1.plot(x, y1, 'b-', alpha=0.5)\n",
        "ax1.axvline(x=mu, color='green', linestyle='--', label='$\\mu$')\n",
        "ax1.axvline(x=sample_mean, color='red', linestyle='--', label='$\\\\bar{x}$')\n",
        "ax1.fill_between(x[(x >= mu-se) & (x <= mu+se)], \n",
        "                 y1[(x >= mu-se) & (x <= mu+se)], \n",
        "                 color='blue', alpha=0.3)\n",
        "ax1.set_title('Confidence Interval centered on $\\mu$')\n",
        "ax1.set_yticks([])\n",
        "ax1.legend()\n",
        "\n",
        "sns.despine(left=True, bottom=False, right=True, top=True, offset=-4, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "4f34a797",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "Perspective 2: probability $\\mu$ is close to $\\bar{x}$\n"
      ],
      "id": "a236a908"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# Setup\n",
        "x = np.linspace(8, 16, 1000)\n",
        "mu = 12\n",
        "sigma = 2.5\n",
        "n = 30\n",
        "se = sigma/np.sqrt(n)\n",
        "\n",
        "fig, ax2 = plt.subplots(1, 1, figsize=(9, 2))\n",
        "\n",
        "# Second plot: μ around x̄\n",
        "sample_mean = 11.6  # Example sample mean\n",
        "y2 = stats.norm.pdf(x, sample_mean, se)\n",
        "ax2.plot(x, y2, 'b-', alpha=0.5)\n",
        "ax2.axvline(x=mu, color='green', linestyle='--', label='$\\mu$')\n",
        "ax2.axvline(x=sample_mean, color='red', linestyle='--', label='$\\\\bar{x}$')\n",
        "ax2.fill_between(x[(x >= sample_mean-se) & (x <= sample_mean+se)], \n",
        "                 y2[(x >= sample_mean-se) & (x <= sample_mean+se)], \n",
        "                 color='blue', alpha=0.3)\n",
        "ax2.set_title('Confidence Interval centered on $\\\\bar{x}$')\n",
        "ax2.set_yticks([])\n",
        "ax2.legend()\n",
        "\n",
        "sns.despine(left=True, bottom=False, right=True, top=True, offset=-4, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "e4a7d6ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "*> if $\\bar{x}$ is in the CI around $\\mu$, then $\\mu$ will be in the CI around $\\bar{x}$! *\n",
        "\n",
        "---\n",
        "\n",
        "## Unknown $\\mu$: Two Perspectives\n",
        "<p class=\"subheader\">There are two mathematically equivalent perspectives to think about \"closeness\" between $\\mu$ and $\\bar{x}$.</p>\n",
        "\n",
        "I repeatedly sampled a distribution and constructed a 95% confidence interval.\n",
        "\n",
        "![](i/Confidence_Intervals_Around_Mean.png){fig-align=\"center\"}\n",
        "\n",
        ". . .\n",
        "\n",
        "*> the samples with $\\bar{x}$ in the CI around $\\mu$ have $\\mu$ in the CI around $\\bar{x}$*\n",
        "\n",
        "---\n",
        "\n",
        "## Unknown $\\mu$: Two Perspectives\n",
        "<p class=\"subheader\">There are two mathematically equivalent perspectives to think about \"closeness\" between $\\mu$ and $\\bar{x}$.</p>\n",
        "\n",
        "I repeatedly sampled a distribution and constructed a 95% confidence interval.\n",
        "\n",
        "![](i/Confidence_Intervals_Around_Mean.png){fig-align=\"center\"}\n",
        "\n",
        "*> it is mathematically equivalent to check whether $\\mu$ is in the CI around $\\bar{x}$!*\n",
        "\n",
        "---\n",
        "\n",
        "## Unknown $\\mu$: How 'close' is $\\mu$ to $\\bar{x}?$\n",
        "<p class=\"subheader\">The distance between $\\bar{x}$ and $\\mu$ works both ways.</p>\n",
        "\n",
        "Now we can use the **Sampling Distribution** around $\\bar{x}$ to know the probability that $\\mu$ is any distance from $\\bar{x}$. \n"
      ],
      "id": "1a6ed4a5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# Setup\n",
        "x = np.linspace(8, 16, 1000)\n",
        "mu = 12\n",
        "sigma = 2.5\n",
        "n = 30\n",
        "se = sigma/np.sqrt(n)\n",
        "\n",
        "fig, ax2 = plt.subplots(1, 1, figsize=(9, 2))\n",
        "\n",
        "# Second plot: μ around x̄\n",
        "sample_mean = 11.6  # Example sample mean\n",
        "y2 = stats.norm.pdf(x, sample_mean, se)\n",
        "ax2.plot(x, y2, 'b-', alpha=0.5)\n",
        "ax2.axvline(x=mu, color='green', linestyle='--', label='$\\mu$')\n",
        "ax2.axvline(x=sample_mean, color='red', linestyle='--', label='$\\\\bar{x}$')\n",
        "ax2.fill_between(x[(x >= sample_mean-se) & (x <= sample_mean+se)], \n",
        "                 y2[(x >= sample_mean-se) & (x <= sample_mean+se)], \n",
        "                 color='blue', alpha=0.3)\n",
        "ax2.set_title('Confidence Interval centered on $\\\\bar{x}$')\n",
        "ax2.set_yticks([])\n",
        "ax2.legend()\n",
        "\n",
        "sns.despine(left=True, bottom=False, right=True, top=True, offset=-4, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "0fc211e8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "*> same distribution shape, just different reference points*\n",
        "\n",
        "---\n",
        "\n",
        "## Unknown $\\mu$: How 'close' is $\\mu$ to $\\bar{x}?$\n",
        "<p class=\"subheader\">Each sample gives us a different $\\bar{x}$ and $S$.</p>\n"
      ],
      "id": "13a7bbab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(123)\n",
        "fig, axes = plt.subplots(1, 5, figsize=(10, 4))\n",
        "\n",
        "mu = 12\n",
        "sigma = 2.5\n",
        "n = 15  # Changed to 15\n",
        "se = sigma/np.sqrt(n)  # Known sigma for sampling distribution\n",
        "\n",
        "for i in range(5):\n",
        "    sample = np.random.normal(mu, sigma, n)\n",
        "    x_bar = np.mean(sample)\n",
        "    s = np.std(sample, ddof=1)\n",
        "    \n",
        "    # Strip plot at x=1\n",
        "    axes[i].scatter(np.ones(n)*0.7, sample, alpha=0.6, s=30)\n",
        "    axes[i].axhline(y=x_bar, color='red', linestyle='--', linewidth=1, zorder=-1, label='$\\\\bar{x}$' if i==0 else '')\n",
        "    axes[i].axhline(y=mu, color='green', linestyle='--', linewidth=1, alpha=1, label='$\\mu$' if i==0 else '')\n",
        "    \n",
        "    # Add sampling distribution centered on x_bar at x=0 (on y-axis)\n",
        "    y_range = np.linspace(x_bar - 4*se, x_bar + 4*se, 200)\n",
        "    x_dist = stats.norm.pdf(y_range, x_bar, se)\n",
        "    # Scale the distribution to fit nicely on the plot\n",
        "    x_dist_scaled = 0.5 * x_dist / max(x_dist)\n",
        "    axes[i].plot(x_dist_scaled, y_range, 'b-', linewidth=2, alpha=0.5)\n",
        "    \n",
        "    # Fill confidence interval (1 SE)\n",
        "    y_ci = y_range[(y_range >= x_bar-se) & (y_range <= x_bar+se)]\n",
        "    x_ci = stats.norm.pdf(y_ci, x_bar, se)\n",
        "    x_ci_scaled = 0.5 * x_ci / max(x_dist)\n",
        "    axes[i].fill_betweenx(y_ci, 0, x_ci_scaled, alpha=0.3, color='blue')\n",
        "    \n",
        "    axes[i].set_xlim(0, 1)\n",
        "    axes[i].set_ylim(7, 17)\n",
        "    axes[i].set_xticks([])\n",
        "    axes[i].set_title(f'x̄={x_bar:.1f}\\ns={s:.1f}', fontsize=12)\n",
        "    if i == 0:\n",
        "        axes[i].set_ylabel('Wait Time (minutes)', fontsize=12)\n",
        "        axes[i].legend(loc='upper left', fontsize=10)\n",
        "\n",
        "sns.despine(left=False, bottom=True, right=True, top=True, offset=0, trim=True)\n",
        "plt.tight_layout()"
      ],
      "id": "1b0d6ce1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "*> notice both $\\bar{x}$ (red lines) and $S$ vary across samples*\n",
        "\n",
        ". . .\n",
        "\n",
        "*> each sample creates its own confidence interval for where $\\mu$ could be*\n",
        "\n",
        ". . .\n",
        "\n",
        "*> now we know the probability $\\mu$ is in the CI around $\\bar{x}$!*\n",
        "\n",
        "---\n",
        "\n",
        "## Unknown $\\sigma$: How 'close' is $\\mu$ to $\\bar{x}?$\n",
        "<p class=\"subheader\">Each sample gives us a different $\\bar{x}$ and $S$.</p>\n"
      ],
      "id": "b22e91ee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(123)\n",
        "fig, axes = plt.subplots(1, 5, figsize=(10, 4))\n",
        "\n",
        "mu = 12\n",
        "sigma = 2.5\n",
        "n = 15  # Changed to 15\n",
        "se = sigma/np.sqrt(n)  # Known sigma for sampling distribution\n",
        "\n",
        "for i in range(5):\n",
        "    sample = np.random.normal(mu, sigma, n)\n",
        "    x_bar = np.mean(sample)\n",
        "    s = np.std(sample, ddof=1)\n",
        "    \n",
        "    # Strip plot at x=1\n",
        "    axes[i].scatter(np.ones(n)*0.7, sample, alpha=0.6, s=30)\n",
        "    axes[i].axhline(y=x_bar, color='red', linestyle='--', linewidth=1, zorder=-1, label='$\\\\bar{x}$' if i==0 else '')\n",
        "    axes[i].axhline(y=mu, color='green', linestyle='--', linewidth=1, alpha=1, label='$\\mu$' if i==0 else '')\n",
        "    \n",
        "    # Add sampling distribution centered on x_bar at x=0 (on y-axis)\n",
        "    y_range = np.linspace(x_bar - 4*se, x_bar + 4*se, 200)\n",
        "    x_dist = stats.norm.pdf(y_range, x_bar, se)\n",
        "    # Scale the distribution to fit nicely on the plot\n",
        "    x_dist_scaled = 0.5 * x_dist / max(x_dist)\n",
        "    axes[i].plot(x_dist_scaled, y_range, 'b-', linewidth=2, alpha=0.5)\n",
        "    \n",
        "    # Fill confidence interval (1 SE)\n",
        "    y_ci = y_range[(y_range >= x_bar-se) & (y_range <= x_bar+se)]\n",
        "    x_ci = stats.norm.pdf(y_ci, x_bar, se)\n",
        "    x_ci_scaled = 0.5 * x_ci / max(x_dist)\n",
        "    axes[i].fill_betweenx(y_ci, 0, x_ci_scaled, alpha=0.3, color='blue')\n",
        "    \n",
        "    axes[i].set_xlim(0, 1)\n",
        "    axes[i].set_ylim(7, 17)\n",
        "    axes[i].set_xticks([])\n",
        "    axes[i].set_title(f'x̄={x_bar:.1f}\\ns={s:.1f}', fontsize=12)\n",
        "    if i == 0:\n",
        "        axes[i].set_ylabel('Wait Time (minutes)', fontsize=12)\n",
        "        axes[i].legend(loc='upper left', fontsize=10)\n",
        "\n",
        "sns.despine(left=False, bottom=True, right=True, top=True, offset=0, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "d4b3b2b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "*> but here we're creating the Confidence Intervals using a known $\\sigma$, which we will never actually observe*\n",
        "\n",
        "*> each sample has a different $S$!*\n",
        "\n",
        "---\n",
        "\n",
        "## Unknown $\\sigma$: Variability of $S$\n",
        "<p class=\"subheader\">Just like $\\bar{x}$ varies around $\\mu$, the $S$ varies around $\\sigma$.</p>\n"
      ],
      "id": "6eda7a02"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "n = 15\n",
        "sigma = 2.5\n",
        "\n",
        "sample_sds = []\n",
        "for _ in range(n_samples):\n",
        "    sample = np.random.normal(12, sigma, n)\n",
        "    sample_sds.append(np.std(sample, ddof=1))\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.hist(sample_sds, bins=30, density=True, alpha=0.7, color='orange')\n",
        "plt.axvline(x=sigma, color='blue', linestyle='--', linewidth=2, label=f'True σ = {sigma}')\n",
        "plt.axvline(x=np.mean(sample_sds), color='red', linestyle='-', linewidth=2, \n",
        "            label=f'Mean of s = {np.mean(sample_sds):.2f}')\n",
        "plt.xlabel('Sample Standard Deviation', fontsize=14)\n",
        "plt.ylabel('', fontsize=14)\n",
        "plt.title(f'Distribution of Sample SD (n={n}, 1000 samples)', fontsize=14)\n",
        "plt.legend()\n",
        "plt.yticks([])\n",
        "\n",
        "sns.despine(left=True, bottom=False, right=True, top=True, offset=0, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "f240151b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "*> we centered the Sampling Distribution on $\\bar{x}$ instead of $\\mu$*\n",
        "\n",
        ". . .\n",
        "\n",
        "*> what would happen if we used the $S$ in place of $\\sigma$ as a guess?*\n",
        "\n",
        "---\n",
        "\n",
        "## Exercise 3.4 | Sampling Variation in $S$\n",
        "<p class=\"subheader\">Will a 90% confidence interval using $S$ in place of $\\sigma$ correctly contain roughly 90% of the population means?</p>\n",
        "\n",
        ". . .\n",
        "\n",
        "Samples ($n=5$) with the sampling distribuion centered on the population mean to show the differences in each samples' spread.\n"
      ],
      "id": "edb1afcf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(123)\n",
        "fig, axes = plt.subplots(1, 7, figsize=(10, 3.5))\n",
        "\n",
        "mu = 12\n",
        "sigma = 2.5\n",
        "n = 5  # Changed to 15\n",
        "\n",
        "for i in range(7):\n",
        "    sample = np.random.normal(mu, sigma, n)\n",
        "    x_bar = np.mean(sample)\n",
        "    s = np.std(sample, ddof=1)\n",
        "    se = s/np.sqrt(n)\n",
        "    \n",
        "    # Strip plot at x=1\n",
        "    axes[i].scatter(np.ones(n)*0.7, sample, alpha=0.6, s=30)\n",
        "    axes[i].axhline(y=mu, color='green', linestyle='--', linewidth=1, alpha=1, label='$\\mu$' if i==0 else '')\n",
        "    \n",
        "    # Add sampling distribution centered on x_bar at x=0 (on y-axis)\n",
        "    y_range = np.linspace(x_bar - 4*se, x_bar + 4*se, 200)\n",
        "    x_dist = stats.norm.pdf(y_range, mu, se)\n",
        "    # Scale the distribution to fit nicely on the plot\n",
        "    x_dist_scaled = 0.5 * x_dist / max(x_dist)\n",
        "    axes[i].plot(x_dist_scaled, y_range, 'b-', linewidth=2, alpha=0.5)\n",
        "    \n",
        "    axes[i].set_xlim(0, 1)\n",
        "    axes[i].set_ylim(6,18)\n",
        "    axes[i].set_xticks([])\n",
        "    axes[i].set_title(f'x̄={x_bar:.1f}\\ns={s:.1f}', fontsize=12)\n",
        "    if i == 0:\n",
        "        axes[i].set_ylabel('Wait Time (minutes)', fontsize=12)\n",
        "        axes[i].legend(loc='upper left', fontsize=10)\n",
        "\n",
        "sns.despine(left=False, bottom=True, right=True, top=True, offset=0, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "b5e0778c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 3.4 | Sampling Variation in $S$\n",
        "<p class=\"subheader\">Will a 90% confidence interval using $S$ in place of $\\sigma$ correctly contain roughly 90% of the population means?</p>\n",
        "\n",
        "\n",
        "<br><br>\n",
        "\n",
        "Simulate many samples and check how often the 90% confidence interval contains the population mean when we simply swap $S$ for $\\sigma$.\n",
        "\n",
        "<br><br>\n",
        "\n",
        ". . .\n",
        "\n",
        "*> theres an additional layer of variability in the sampling distribution coming from the variability in the sample standard deviation ($S$)*\n",
        "\n",
        "---\n",
        "\n",
        "## Exercise 3.4 | Sampling Variation in $S$\n",
        "<p class=\"subheader\">Using the normal distribution with $S$ gives wrong coverage rates (n=15).</p>\n"
      ],
      "id": "98378b9c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(421)\n",
        "n_simulations = 1000\n",
        "n = 15\n",
        "mu = 12\n",
        "sigma = 2.5\n",
        "confidence_level = 0.90\n",
        "\n",
        "# Track coverage\n",
        "normal_coverage = []\n",
        "t_coverage = []\n",
        "\n",
        "for _ in range(n_simulations):\n",
        "    sample = np.random.normal(mu, sigma, n)\n",
        "    x_bar = np.mean(sample)\n",
        "    s = np.std(sample, ddof=1)\n",
        "    se = s / np.sqrt(n)\n",
        "    \n",
        "    # Normal CI (incorrect)\n",
        "    z_crit = stats.norm.ppf((1 + confidence_level) / 2)\n",
        "    normal_ci_lower = x_bar - z_crit * se\n",
        "    normal_ci_upper = x_bar + z_crit * se\n",
        "    normal_coverage.append(normal_ci_lower <= mu <= normal_ci_upper)\n",
        "    \n",
        "    # t CI (correct)\n",
        "    t_crit = stats.t.ppf((1 + confidence_level) / 2, df=n-1)\n",
        "    t_ci_lower = x_bar - t_crit * se\n",
        "    t_ci_upper = x_bar + t_crit * se\n",
        "    t_coverage.append(t_ci_lower <= mu <= t_ci_upper)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot coverage rates\n",
        "categories = ['Normal\\n(too confident)', 't-distribution\\n(correct)']\n",
        "coverage_rates = [np.mean(normal_coverage), np.mean(t_coverage)]\n",
        "colors = ['red', 'green']\n",
        "\n",
        "bars = ax1.bar(categories, coverage_rates, color=colors, alpha=0.7)\n",
        "ax1.axhline(y=0.9, color='blue', linestyle='--', label='Target: 90%')\n",
        "ax1.set_ylabel('')\n",
        "ax1.set_title('Coverage of 90% Confidence Intervals', fontsize=14)\n",
        "ax1.set_ylim(0.8, 1.0)\n",
        "ax1.legend()\n",
        "\n",
        "# Add text labels\n",
        "for bar, rate in zip(bars, coverage_rates):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
        "             f'{rate:.1%}', ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "# Show distribution comparison\n",
        "x = np.linspace(-3, 3, 1000)\n",
        "for n,a in zip([3,5,30,200],[0.1,0.3,0.6,0.8]):\n",
        "    ax2.plot(x, stats.t.pdf(x, df=n-1), 'g-', label=f't (df={n-1})', alpha=a)\n",
        "ax2.plot(x, stats.norm.pdf(x), 'r--', label='Normal', alpha=0.7)\n",
        "ax2.set_xlabel('Standard Errors from Mean', fontsize=14)\n",
        "ax2.set_ylabel('')\n",
        "ax2.set_yticks([])\n",
        "ax2.set_title('t-Distribution approaches Normal', fontsize=14)\n",
        "ax2.legend()\n",
        "\n",
        "sns.despine(left=False, bottom=False, right=True, top=True, offset=0, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "e0234433",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "*> we would predict 90% when the actual number is lower (87.5%)*\n",
        "\n",
        ". . .\n",
        "\n",
        "*> we would be **too confident** if we use the Normal with $S/\\sqrt{n}$*\n",
        "\n",
        "---\n",
        "\n",
        "## Exercise 3.4 | Sampling Variation in $S$\n",
        "<p class=\"subheader\">Will a 90% confidence interval using $S$ in place of $\\sigma$ correctly contain roughly 90% of the population means?</p>\n",
        "\n",
        ". . .\n",
        "\n",
        "Samples ($n=5$) with the sampling distribuion centered on the population mean to show the differences in each samples' spread.\n"
      ],
      "id": "89cc3def"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(123)\n",
        "fig, axes = plt.subplots(1, 7, figsize=(10, 3.5))\n",
        "\n",
        "mu = 12\n",
        "sigma = 2.5\n",
        "n = 5  # Changed to 15\n",
        "\n",
        "for i in range(7):\n",
        "    sample = np.random.normal(mu, sigma, n)\n",
        "    x_bar = np.mean(sample)\n",
        "    s = np.std(sample, ddof=1)\n",
        "    se = s/np.sqrt(n)\n",
        "    \n",
        "    # Strip plot at x=1\n",
        "    axes[i].scatter(np.ones(n)*0.7, sample, alpha=0.6, s=30)\n",
        "    axes[i].axhline(y=mu, color='green', linestyle='--', linewidth=1, alpha=1, label='$\\mu$' if i==0 else '')\n",
        "    \n",
        "    # Add sampling distribution centered on x_bar at x=0 (on y-axis)\n",
        "    y_range = np.linspace(x_bar - 4*se, x_bar + 4*se, 200)\n",
        "    x_dist = stats.norm.pdf(y_range, mu, se)\n",
        "    # Scale the distribution to fit nicely on the plot\n",
        "    x_dist_scaled = 0.5 * x_dist / max(x_dist)\n",
        "    axes[i].plot(x_dist_scaled, y_range, 'b-', linewidth=2, alpha=0.5)\n",
        "    \n",
        "    axes[i].set_xlim(0, 1)\n",
        "    axes[i].set_ylim(6,18)\n",
        "    axes[i].set_xticks([])\n",
        "    axes[i].set_title(f'x̄={x_bar:.1f}\\ns={s:.1f}', fontsize=12)\n",
        "    if i == 0:\n",
        "        axes[i].set_ylabel('Wait Time (minutes)', fontsize=12)\n",
        "        axes[i].legend(loc='upper left', fontsize=10)\n",
        "\n",
        "sns.despine(left=False, bottom=True, right=True, top=True, offset=0, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "153c0ac3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 3.4 | Sampling Variation in $S$\n",
        "<p class=\"subheader\">Will a 90% confidence interval using $S$ in place of $\\sigma$ correctly contain roughly 90% of the population means?</p>\n",
        "\n",
        "Samples ($n=30$) with the sampling distribuion centered on the population mean to show the differences in each samples' spread.\n"
      ],
      "id": "74a54c79"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(123)\n",
        "fig, axes = plt.subplots(1, 7, figsize=(10, 3.5))\n",
        "\n",
        "mu = 12\n",
        "sigma = 2.5\n",
        "n = 30  # Changed to 15\n",
        "\n",
        "for i in range(7):\n",
        "    sample = np.random.normal(mu, sigma, n)\n",
        "    x_bar = np.mean(sample)\n",
        "    s = np.std(sample, ddof=1)\n",
        "    se = s/np.sqrt(n)\n",
        "    \n",
        "    # Strip plot at x=1\n",
        "    axes[i].scatter(np.ones(n)*0.7, sample, alpha=0.6, s=30)\n",
        "    axes[i].axhline(y=mu, color='green', linestyle='--', linewidth=1, alpha=1, label='$\\mu$' if i==0 else '')\n",
        "    \n",
        "    # Add sampling distribution centered on x_bar at x=0 (on y-axis)\n",
        "    y_range = np.linspace(x_bar - 4*se, x_bar + 4*se, 200)\n",
        "    x_dist = stats.norm.pdf(y_range, mu, se)\n",
        "    # Scale the distribution to fit nicely on the plot\n",
        "    x_dist_scaled = 0.5 * x_dist / max(x_dist)\n",
        "    axes[i].plot(x_dist_scaled, y_range, 'b-', linewidth=2, alpha=0.5)\n",
        "    \n",
        "    axes[i].set_xlim(0, 1)\n",
        "    axes[i].set_ylim(6,18)\n",
        "    axes[i].set_xticks([])\n",
        "    axes[i].set_title(f'x̄={x_bar:.1f}\\ns={s:.1f}', fontsize=12)\n",
        "    if i == 0:\n",
        "        axes[i].set_ylabel('Wait Time (minutes)', fontsize=12)\n",
        "        axes[i].legend(loc='upper left', fontsize=10)\n",
        "\n",
        "sns.despine(left=False, bottom=True, right=True, top=True, offset=0, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "3b10e90e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*> as the sample size grows (now n=30), this variability gets smaller*\n",
        "\n",
        ". . .\n",
        "\n",
        "*> but we'll always use a t-Distribution instead of a Normal for testing*\n",
        "\n",
        "---\n",
        "\n",
        "## Unknown $\\mu$ and $\\sigma$: Building Models\n",
        "<p class=\"subheader\">What if we want to test a specific claim about the unobserved population mean?</p>\n",
        "\n",
        "<br>\n",
        "\n",
        ". . .\n",
        "\n",
        "Is our data consistent with the following specific claim?\n",
        "\n",
        "- \"The mean wait time is 10 minutes.\"\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "*> instead of finding where some $\\mu$ might be, we're testing a specific value of $\\mu$*\n",
        "\n",
        "---\n",
        "\n",
        "## Example: Wait Times\n",
        "<p class=\"subheader\">If $\\bar{x}=10.85$, is that consistent with $\\mu_0=10$?</p>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"60%\"}\n",
        "If sample standard deviation is $s = 2.5$:\n",
        "\n",
        "$$SE = \\frac{s}{\\sqrt{n}}$$\n",
        "\n",
        "$$SE = \\frac{2.5}{\\sqrt{30}}$$\n",
        "\n",
        "$$SE = 0.456$$\n",
        ":::\n",
        "\n",
        "::: {.column width=\"40%\"}"
      ],
      "id": "90d85f59"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "mu_0 = 10\n",
        "std_err = 2.5/np.sqrt(30)\n",
        "observed_mean = 10.85\n",
        "df = 29  # degrees of freedom = n-1\n",
        "\n",
        "x = np.linspace(mu_0-3*std_err, mu_0+3*std_err, 1000)\n",
        "y = stats.t.pdf(x, df, loc=mu_0, scale=std_err)\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, y, 'r-', linewidth=2)\n",
        "plt.axvline(x=mu_0, color='blue', linestyle='--', linewidth=1)\n",
        "\n",
        "# Shade the confidence interval\n",
        "t_critical = stats.t.ppf(0.975, df)  # t-value for 95% CI\n",
        "ci_lower = mu_0 - t_critical * std_err\n",
        "ci_upper = mu_0 + t_critical * std_err\n",
        "plt.fill_between(x[(x >= ci_lower) & (x <= ci_upper)], \n",
        "                 0, \n",
        "                 y[(x >= ci_lower) & (x <= ci_upper)], \n",
        "                 color='blue', alpha=0.2)\n",
        "\n",
        "# Mark the observed mean\n",
        "plt.axvline(x=observed_mean, color='green', linestyle='-', linewidth=2)\n",
        "\n",
        "plt.yticks([])\n",
        "plt.title('t-Distribution if μ=10 (df=29)')\n",
        "\n",
        "sns.despine(left=True, bottom=False, right=True, top=True, offset=-7, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "c924d745",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "```python\n",
        "s = 2.5\n",
        "n = 30\n",
        "se = s / np.sqrt(30)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Example: Wait Times\n",
        "<p class=\"subheader\">The math to answer this question is identical to confidence intervals.</p>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"60%\"}\n",
        "If sample standard deviation is $s = 2.5$:\n",
        "\n",
        "$$SE = 0.456$$\n",
        "\n",
        "If true mean is $\\mu_0 = 10$:\n",
        "\n",
        "$$\\bar{x} \\sim t_{29}(10, 0.456)$$\n",
        "\n",
        "So the critical value for 95%:\n",
        "$$t_{crit} = 2.045$$\n",
        ":::\n",
        "\n",
        "::: {.column width=\"40%\"}"
      ],
      "id": "f201a9b3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "mu_0 = 10\n",
        "std_err = 2.5/np.sqrt(30)\n",
        "observed_mean = 10.85\n",
        "df = 29  # degrees of freedom = n-1\n",
        "\n",
        "x = np.linspace(mu_0-3*std_err, mu_0+3*std_err, 1000)\n",
        "y = stats.t.pdf(x, df, loc=mu_0, scale=std_err)\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, y, 'r-', linewidth=2)\n",
        "plt.axvline(x=mu_0, color='blue', linestyle='--', linewidth=1)\n",
        "\n",
        "# Shade the confidence interval\n",
        "t_critical = stats.t.ppf(0.975, df)  # t-value for 95% CI\n",
        "ci_lower = mu_0 - t_critical * std_err\n",
        "ci_upper = mu_0 + t_critical * std_err\n",
        "plt.fill_between(x[(x >= ci_lower) & (x <= ci_upper)], \n",
        "                 0, \n",
        "                 y[(x >= ci_lower) & (x <= ci_upper)], \n",
        "                 color='blue', alpha=0.2)\n",
        "\n",
        "# Mark the observed mean\n",
        "plt.axvline(x=observed_mean, color='green', linestyle='-', linewidth=2)\n",
        "\n",
        "plt.yticks([])\n",
        "plt.title('t-Distribution if μ=10 (df=29)')\n",
        "\n",
        "sns.despine(left=True, bottom=False, right=True, top=True, offset=-7, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "d1280531",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "```python\n",
        "stats.t.interval(0.95, df=30)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Example: Wait Times\n",
        "<p class=\"subheader\">The math to answer this question is identical to confidence intervals.</p>\n"
      ],
      "id": "2b385e5a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "mu_0 = 10\n",
        "std_err = 2.5/np.sqrt(30)\n",
        "observed_mean = 10.85\n",
        "df = 29  # degrees of freedom = n-1\n",
        "\n",
        "x = np.linspace(mu_0-3*std_err, mu_0+3*std_err, 1000)\n",
        "y = stats.t.pdf(x, df, loc=mu_0, scale=std_err)\n",
        "\n",
        "plt.figure(figsize=(11, 3))\n",
        "plt.plot(x, y, 'r-', linewidth=2)\n",
        "plt.axvline(x=mu_0, color='blue', linestyle='--', linewidth=1)\n",
        "\n",
        "# Shade the confidence interval\n",
        "t_critical = stats.t.ppf(0.975, df)  # t-value for 95% CI\n",
        "ci_lower = mu_0 - t_critical * std_err\n",
        "ci_upper = mu_0 + t_critical * std_err\n",
        "plt.fill_between(x[(x >= ci_lower) & (x <= ci_upper)], \n",
        "                 0, \n",
        "                 y[(x >= ci_lower) & (x <= ci_upper)], \n",
        "                 color='blue', alpha=0.2)\n",
        "\n",
        "# Mark the observed mean\n",
        "plt.axvline(x=observed_mean, color='green', linestyle='-', linewidth=2)\n",
        "plt.annotate(f'Observed\\nMean: {observed_mean}', xy=(observed_mean, 0.5),\n",
        "             xytext=(observed_mean+0.3, 1.0), fontsize=12,\n",
        "             arrowprops=dict(facecolor='black', shrink=0.05, width=1.5))\n",
        "\n",
        "plt.yticks([])\n",
        "plt.title('t-Distribution if μ=10 (df=29)')\n",
        "\n",
        "sns.despine(left=True, bottom=False, right=True, top=True, offset=-7, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "76ca2663",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A 95% confidence interval around $\\mu_0$ would be: $[9.07, 10.93]$\n",
        "\n",
        ". . .\n",
        "\n",
        "*> our observed mean ($\\bar{x} = 10.85$) is within this interval — not surprising if μ=10*\n",
        "\n",
        ". . .\n",
        "\n",
        "*> but if we observed $\\bar{x} = 11.5$, that would be outside the interval — surprising!*\n",
        "\n",
        "---\n",
        "\n",
        "## The Null Hypothesis\n",
        "<p class=\"subheader\">We formalize this approach by setting up a \"null hypothesis\"</p>\n",
        "\n",
        "<br>\n",
        "\n",
        ". . .\n",
        "\n",
        "**Null Hypothesis** ($H_0$): *The specific value or claim we're testing*\n",
        "\n",
        ". . .\n",
        "\n",
        "- $H_0: \\mu = 10$ (wait time is 10 minutes)\n",
        "\n",
        ". . .\n",
        "\n",
        "**Alternative Hypothesis** ($H_1$ or $H_a$): *What we accept if we reject the null*\n",
        "\n",
        ". . .\n",
        "\n",
        "- $H_1: \\mu \\neq 10$ (wait time is not 10 minutes)\n",
        "\n",
        ". . .\n",
        "\n",
        "**Testing Approach**: \n",
        "\n",
        "- Calculate how \"surprising\" our data would be if $H_0$ were true\n",
        "- If sufficiently surprising, we reject $H_0$\n",
        "\n",
        "---\n",
        "\n",
        "## Quantifying Surprise: p-values\n",
        "<p class=\"subheader\">The p-value measures how compatible our data is with the null hypothesis.</p>\n",
        "\n",
        "<br>\n",
        "\n",
        ". . .\n",
        "\n",
        "**p-value**: *The probability of observing a test statistic at least as extreme as ours, if the null hypothesis were true*\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "**For our example:**\n",
        "\n",
        "- Null: $\\mu = 10$\n",
        "\n",
        ". . .\n",
        "\n",
        "- Observed: $\\bar{x} = 10.85$\n",
        "\n",
        ". . .\n",
        "\n",
        "*> How likely is it to get $\\bar{x}$ this far or farther from 10, if the true mean is 10?*\n",
        "\n",
        "---\n",
        "\n",
        "## Quantifying Surprise: p-values\n",
        "<p class=\"subheader\">Example cont.: What is the probability of an error as large as the observed mean?</p>\n",
        "\n",
        "*> how likely is it to get $\\bar{x}$ this far or farther from 10, if the true mean is 10?*\n"
      ],
      "id": "3c9e8b7d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| fig-align: center\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "mu_0 = 10\n",
        "std_err = 2.5/np.sqrt(30)\n",
        "observed_mean = 10.85\n",
        "\n",
        "x = np.linspace(mu_0-3*std_err, mu_0+3*std_err, 1000)\n",
        "y = stats.norm.pdf(x, mu_0, std_err)\n",
        "\n",
        "# Calculate two-tailed p-value\n",
        "z_score = (observed_mean - mu_0) / std_err\n",
        "p_value = stats.t.cdf((mu_0-observed_mean)/se, df=29) * 2\n",
        "\n",
        "plt.figure(figsize=(11, 3))\n",
        "plt.plot(x, y, 'r-', linewidth=2)\n",
        "plt.axvline(x=mu_0, color='blue', linestyle='--', linewidth=1)\n",
        "\n",
        "# Mark the observed mean\n",
        "plt.axvline(x=observed_mean, color='green', linestyle='-', linewidth=2)\n",
        "plt.annotate(f'Observed\\nMean: {observed_mean}', xy=(observed_mean, 0.5),\n",
        "             xytext=(observed_mean+0.3, 1.0), fontsize=12,\n",
        "             arrowprops=dict(facecolor='black', shrink=0.05, width=1.5))\n",
        "\n",
        "# Shade the area representing the p-value\n",
        "x_right = np.linspace(observed_mean, mu_0+3*std_err, 500)\n",
        "y_right = stats.norm.pdf(x_right, mu_0, std_err)\n",
        "plt.fill_between(x_right, 0, y_right, color='red', alpha=0.3)\n",
        "\n",
        "x_left = np.linspace(mu_0-3*std_err, mu_0-(observed_mean-mu_0), 500)\n",
        "y_left = stats.norm.pdf(x_left, mu_0, std_err)\n",
        "plt.fill_between(x_left, 0, y_left, color='red', alpha=0.3)\n",
        "\n",
        "plt.annotate(f'p-value = {p_value:.3f}', xy=(mu_0, 0.4),\n",
        "             xytext=(mu_0, 0.6), fontsize=14, ha='center',\n",
        "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
        "\n",
        "plt.title('Two-tailed Test for μ=10', fontsize=16)\n",
        "plt.xlabel('Sample Mean (minutes)', fontsize=14)\n",
        "plt.yticks([])\n",
        "\n",
        "sns.despine(left=True, bottom=False, right=True, top=True, offset=-5, trim=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "7befc92c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "```python\n",
        "stats.t.cdf((mu_0-xbar)/se, df=n-1)) * 2\n",
        "```\n",
        "\n",
        ". . .\n",
        "\n",
        "*> interpretation: if μ=10, we'd see $\\bar{x}$ this far from 10 about 7.2% of the time*\n",
        "\n",
        ". . .\n",
        "\n",
        "*> often, we reject $H_0$ if p-value < 0.05 (5%)*\n",
        "\n",
        ". . .\n",
        "\n",
        "*> here, p-value > 0.05, so we don't reject the claim that μ=10*\n",
        "\n",
        "---\n",
        "\n",
        "## Test Statistic: The t-statistic\n",
        "<p class=\"subheader\">We can standardize our result for easier interpretation</p>\n",
        "\n",
        ". . .\n",
        "\n",
        "The **t-statistic** measures how many standard errors our sample mean is from the null value:\n",
        "\n",
        ". . .\n",
        "\n",
        "$$t = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}$$\n",
        "\n",
        ". . .\n",
        "\n",
        "Where:\n",
        "\n",
        "- $\\bar{x}$ is our sample mean (10.85)\n",
        "- $\\mu_0$ is our null value (10)\n",
        "- $s$ is our sample standard deviation (2.5)\n",
        "- $n$ is our sample size (30)\n",
        "\n",
        "---\n",
        "\n",
        "## Test Statistic: The t-statistic\n",
        "<p class=\"subheader\">We can standardize our result for easier interpretation</p>\n",
        "\n",
        "The **t-statistic** measures how many standard errors our sample mean is from the null value:\n",
        "\n",
        "$$t = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}} = \\frac{10.85 - 10}{2.5/\\sqrt{30}} = \\frac{0.85}{0.456} = 1.86$$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $\\bar{x}$ is our sample mean (10.85)\n",
        "- $\\mu_0$ is our null value (10)\n",
        "- $s$ is our sample standard deviation (2.5)\n",
        "- $n$ is our sample size (30)\n",
        "\n",
        "---\n",
        "\n",
        "## The t-test\n",
        "<p class=\"subheader\">This example has become a formal hypothesis test.</p>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"40%\"}\n",
        "**One-sample t-test:**\n",
        "\n",
        "- $H_0: \\mu = 10$  \n",
        "- $H_1: \\mu \\neq 10$\n",
        "- Test statistic: $t = 1.86$\n",
        "- Degrees of freedom: 29\n",
        "- p-value: 0.072\n",
        "\n",
        "**Decision rule:**\n",
        "\n",
        "- If p-value < 0.05, reject $H_0$\n",
        "- Otherwise, fail to reject $H_0$\n",
        ":::\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "```python\n",
        "# Imports\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "```python\n",
        "# Sample Data\n",
        "sample_mu = 10.85\n",
        "pop_mu = 10    # null hypothesis\n",
        "std_dev = 2.5    \n",
        "n = 30\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "```python\n",
        "# Calculate t-statistic\n",
        "t_stat = (sample_mu - pop_mu) / (std_dev / np.sqrt(n))\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "```python\n",
        "# Calculate p-value\n",
        "p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=n-1))\n",
        "```\n",
        ":::\n",
        "::::\n",
        "\n",
        ". . .\n",
        "\n",
        "*> t-tests are a univariate version of regression*\n",
        "\n",
        "---\n",
        "\n",
        "## Statistical vs. Practical Significance\n",
        "<p class=\"subheader\">A caution about hypothesis testing</p>\n",
        "\n",
        "<br>\n",
        "\n",
        ". . .\n",
        "\n",
        "**Statistical significance:**\n",
        "\n",
        "- Formal rejection of the null hypothesis (p < 0.05)\n",
        "- Only tells us if the effect is unlikely due to chance\n",
        "\n",
        ". . .\n",
        "\n",
        "**Practical significance:**\n",
        "\n",
        "- Whether the effect size matters in the real world\n",
        "- A statistically significant result can still be tiny\n",
        "\n",
        ". . .\n",
        "\n",
        "*> with large samples, even tiny differences can be statistically significant*\n",
        "\n",
        ". . .\n",
        "\n",
        "*> always consider the magnitude of the effect, not just the p-value*\n",
        "\n",
        "---\n",
        "\n",
        "## Common Misinterpretations\n",
        "<p class=\"subheader\">What a p-value is NOT</p>\n",
        "\n",
        "<br>\n",
        "\n",
        "❌ **Not:** The probability that $H_0$ is true\n",
        "\n",
        "   - The p-value doesn't tell us if the null hypothesis is correct. It assumes the null is true and then calculates how surprising our result would be under that assumption.\n",
        "   - *Example:* A p-value of 0.04 doesn't mean there's a 4% chance the null hypothesis is true.\n",
        "\n",
        "---\n",
        "\n",
        "## Common Misinterpretations\n",
        "<p class=\"subheader\">What a p-value is NOT</p>\n",
        "\n",
        "<br>\n",
        "\n",
        "❌ **Not:** The probability that the results occurred by chance\n",
        "\n",
        "   - All results reflect some combination of real effects and random variation. The p-value doesn't separate these components.\n",
        "   - *Example:* A p-value of 0.04 doesn't mean there's a 4% chance our results are due to chance and 96% chance they're real.\n",
        "\n",
        "---\n",
        "\n",
        "## Common Misinterpretations\n",
        "<p class=\"subheader\">What a p-value is NOT</p>\n",
        "\n",
        "<br>\n",
        "\n",
        "❌ **Not:** The probability that $H_1$ is true\n",
        "\n",
        "   - The p-value doesn't directly address the alternative hypothesis or its likelihood.\n",
        "   - *Example:* A p-value of 0.04 doesn't mean there's a 96% chance the alternative hypothesis is true.\n",
        "\n",
        "---\n",
        "\n",
        "## Common Misinterpretations\n",
        "<p class=\"subheader\">What a p-value is NOT</p>\n",
        "\n",
        "<br>\n",
        "\n",
        "✅ **Correct:** The probability of observing a test statistic at least as extreme as ours, if $H_0$ were true\n",
        "\n",
        "   - It measures the compatibility between our data and the null hypothesis.\n",
        "   - *Example:* A p-value of 0.04 means: \"If the null hypothesis were true, we'd see results this extreme or more extreme only about 4% of the time.\"\n",
        "\n",
        "*> think of it like this: The p-value answers \"How surprising is this data if the null hypothesis is true?\" not \"Is the null hypothesis true?\"*\n",
        "\n",
        "---\n",
        "\n",
        "## Looking Forward: Bivariate GLM\n",
        "<p class=\"subheader\">This framework extends directly to regression analysis.</p>\n",
        "\n",
        "<br>\n",
        "\n",
        ". . .\n",
        "\n",
        "**Next time:**\n",
        "\n",
        "- Bivariate GLM: Comparing means between two groups\n",
        "\n",
        ". . .\n",
        "\n",
        "*> the hypothesis testing framework is foundational for modern science*\n",
        "\n",
        "---\n",
        "\n",
        "## Looking Forward: Regression\n",
        "<p class=\"subheader\">This framework extends directly to regression analysis.</p>\n",
        "\n",
        ". . .\n",
        "\n",
        "**Today's model**: $E[y] = \\beta_0$ (just an intercept)\n",
        "\n",
        ". . .\n",
        "\n",
        "**Next:** $E[y] = \\beta_0 + \\beta_1 x$ (intercept and slope)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Each $\\beta$ coefficient will have its own t-test\n",
        "- Same framework: estimate ± t-critical × SE\n",
        "- The t-distribution accounts for uncertainty in our estimates\n",
        "\n",
        ". . .\n",
        "\n",
        "*> regression is just an extension of what we learned today*\n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "<p class=\"subheader\">We've built the foundation for statistical modeling.</p>\n",
        "\n",
        "<br>\n",
        "\n",
        ":::{.incremental}\n",
        "- Flipped perspective: center on what we observe ($\\bar{x}$) not what's unknown ($\\mu$)\n",
        "- Sample SD varies, creating need for t-distribution\n",
        "- Built our first model: $E[y] = \\beta_0$\n",
        "- Tested hypotheses by shifting data\n",
        "- Connected hypothesis tests to confidence intervals\n",
        ":::\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "*> these tools form the foundation of econometric analysis*"
      ],
      "id": "24d544f4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}