{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation as a Tool (Python Version)\n",
    "\n",
    "Similar to our numerical approach to solving equations and optimizing problems, we might also struggle to deal with the analytical complexities of transforming our results.\n",
    "\n",
    "Even where we **can** probably calculate something if we thought about it long enough, the time it takes to do this could have been dedicated to running a quick simulation and getting a ballpark on the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import utils\n",
    "\n",
    "# Set up plotting style\n",
    "utils.set_pitt_style()\n",
    "PITT_BLUE = utils.PITT_BLUE\n",
    "PITT_GOLD = utils.PITT_GOLD\n",
    "PITT_GRAY = utils.PITT_GRAY\n",
    "PITT_LGRAY = utils.PITT_LGRAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Law of Large Numbers\n",
    "\n",
    "The fundamental idea here is that we make use of the law of large numbers.\n",
    "\n",
    "For an iid sample $(X_1, X_2, \\ldots, X_n)$ with mean $\\mu_X$ and variance $\\sigma^2_X$, the LLN tells us that for any positive difference $\\epsilon$ as $n \\rightarrow \\infty$:\n",
    "$$\\Pr\\left\\{\\left| \\overline X_n-\\mu_X \\right|>\\epsilon \\right\\} \\rightarrow 0 $$\n",
    "\n",
    "### Simulation as a brute-force calculator\n",
    "\n",
    "If there's a value $\\mu$ that we'd like to approximate, if we can construct a random variable $X$ with $\\mathbb{E}X = \\mu$, then one option is simply to simulate it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Calculating Pi\n",
    "\n",
    "A simple geometric problem is trying to calculate the value of $\\pi$.\n",
    "\n",
    "### Analytical approach: Nilakantha Series\n",
    "$$\\pi = 3 + \\frac{4}{2\\times 3\\times 4}-\\frac{4}{4\\times 5\\times 6}+\\frac{4}{6\\times 7\\times 8} + \\ldots$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nilakantha_pi(n):\n",
    "    \"\"\"Calculate pi using the Nilakantha series.\"\"\"\n",
    "    x = 3.0\n",
    "    for k in range(1, n + 1):\n",
    "        x += 4 * ((-1) ** (k + 1)) / ((1 + 2*k)**3 - (1 + 2*k))\n",
    "    return x\n",
    "\n",
    "# Test it\n",
    "print(f\"nilakantha_pi(200) = {nilakantha_pi(200):.10f}\")\n",
    "print(f\"Actual pi          = {np.pi:.10f}\")\n",
    "print(f\"Error              = {abs(np.pi - nilakantha_pi(200)):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence of Nilakantha series\n",
    "ns = np.arange(3, 201)\n",
    "pi_estimates = [nilakantha_pi(n) for n in ns]\n",
    "errors = np.abs(np.pi - np.array(pi_estimates))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(ns, errors, color=PITT_BLUE, s=20)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('n (number of terms)')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Convergence of Nilakantha Series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation approach: Monte Carlo\n",
    "\n",
    "We can estimate $\\pi$ using simulation by drawing random points and checking if they fall inside a circle.\n",
    "\n",
    "Draw $(U_1, U_2)$ uniformly from $[-1, 1]^2$ and define:\n",
    "$$ X = \\begin{cases} 4 & \\text{if } U_1^2 + U_2^2 \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases} $$\n",
    "\n",
    "Then $\\mathbb{E}X = \\Pr\\{(U_1, U_2) \\text{ in circle}\\} \\cdot 4 = \\frac{\\pi \\cdot 1^2}{2 \\times 2} \\cdot 4 = \\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R: runif(n, min=-1, max=1)\n",
    "# Python: np.random.uniform(-1, 1, n)\n",
    "\n",
    "n = 10000\n",
    "u1 = np.random.uniform(-1, 1, n)\n",
    "u2 = np.random.uniform(-1, 1, n)\n",
    "\n",
    "# R: ifelse((u1**2 + u2**2) <= 1, 4, 0)\n",
    "# Python: np.where((u1**2 + u2**2) <= 1, 4, 0)\n",
    "in_circle = np.where((u1**2 + u2**2) <= 1, 4, 0)\n",
    "\n",
    "pi_estimate = np.mean(in_circle)\n",
    "print(f\"Pi estimate with n={n}: {pi_estimate:.6f}\")\n",
    "print(f\"Actual pi: {np.pi:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Monte Carlo simulation\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "in_mask = (u1**2 + u2**2) <= 1\n",
    "ax.scatter(u1[in_mask], u2[in_mask], color=PITT_GOLD, s=1, alpha=0.5, label='Inside circle')\n",
    "ax.scatter(u1[~in_mask], u2[~in_mask], color=PITT_BLUE, s=1, alpha=0.5, label='Outside circle')\n",
    "\n",
    "# Draw circle\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "ax.plot(np.cos(theta), np.sin(theta), 'k-', linewidth=2)\n",
    "\n",
    "ax.set_xlim(-1.1, 1.1)\n",
    "ax.set_ylim(-1.1, 1.1)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend()\n",
    "ax.set_title(f'Monte Carlo Pi Estimation (n={n})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence with sample size\n",
    "def pi_sim(n):\n",
    "    \"\"\"Estimate pi using Monte Carlo with n samples.\"\"\"\n",
    "    u1 = np.random.uniform(-1, 1, n)\n",
    "    u2 = np.random.uniform(-1, 1, n)\n",
    "    return np.mean(np.where((u1**2 + u2**2) <= 1, 4, 0))\n",
    "\n",
    "# Test with increasing sample sizes\n",
    "sample_sizes = 10 ** np.arange(3, 8)\n",
    "pi_estimates = [pi_sim(n) for n in sample_sizes]\n",
    "errors = np.abs(np.pi - np.array(pi_estimates))\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'n': sample_sizes,\n",
    "    'pi_estimate': pi_estimates,\n",
    "    'error': errors\n",
    "})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(results['n'], results['error'], color=PITT_BLUE, s=100)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Sample size (n)')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Monte Carlo Pi Convergence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electoral College Simulation\n",
    "\n",
    "A more complex example: forecasting US presidential elections. The winner is determined by electoral votes from each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from The Economist model\n",
    "economist_data = pd.read_csv('economist/state_averages_and_predictions_topline.csv')\n",
    "ev_data = pd.read_csv('ev.csv')\n",
    "\n",
    "print(\"Economist Data:\")\n",
    "print(economist_data.head())\n",
    "print(\"\\nElectoral Votes:\")\n",
    "print(ev_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create state probability dataframe\n",
    "state_prob = economist_data[['state', 'projected_win_prob']].copy()\n",
    "state_prob.columns = ['state', 'dem_prob']\n",
    "state_prob['rep_prob'] = 1 - state_prob['dem_prob']\n",
    "\n",
    "# Merge with electoral votes\n",
    "state_prob = state_prob.merge(ev_data, on='state')\n",
    "state_prob = state_prob.set_index('state')\n",
    "\n",
    "print(state_prob.head())\n",
    "state_list = state_prob.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_draw(prob_list, ev_list):\n",
    "    \"\"\"\n",
    "    Simulate one election outcome.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prob_list : array-like\n",
    "        Democratic win probability for each state\n",
    "    ev_list : array-like\n",
    "        Electoral votes for each state\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Election outcome with dem and rep totals\n",
    "    \"\"\"\n",
    "    n_states = len(prob_list)\n",
    "    rnd = np.random.uniform(0, 1, n_states)\n",
    "    \n",
    "    # Dem wins state if random < probability\n",
    "    dem_wins = rnd < np.array(prob_list)\n",
    "    dem_ev = np.sum(np.array(ev_list) * dem_wins)\n",
    "    \n",
    "    return {\n",
    "        'dem_total': dem_ev,\n",
    "        'rep_total': 538 - dem_ev\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test one draw\n",
    "result = state_draw(state_prob['dem_prob'].values, state_prob['ev'].values)\n",
    "print(f\"Democratic EV: {result['dem_total']}\")\n",
    "print(f\"Republican EV: {result['rep_total']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation many times\n",
    "# R: n.sims <- 500000\n",
    "# Python: vectorized approach is much faster\n",
    "\n",
    "n_sims = 100000\n",
    "\n",
    "def run_election_simulation(prob_list, ev_list, n_sims):\n",
    "    \"\"\"Run multiple election simulations.\"\"\"\n",
    "    n_states = len(prob_list)\n",
    "    \n",
    "    # Generate all random numbers at once (much faster than loop)\n",
    "    rnd = np.random.uniform(0, 1, (n_sims, n_states))\n",
    "    \n",
    "    # Compare to probabilities\n",
    "    dem_wins = rnd < np.array(prob_list)\n",
    "    \n",
    "    # Calculate totals\n",
    "    dem_totals = np.sum(dem_wins * np.array(ev_list), axis=1)\n",
    "    \n",
    "    return dem_totals\n",
    "\n",
    "dem_totals = run_election_simulation(\n",
    "    state_prob['dem_prob'].values, \n",
    "    state_prob['ev'].values, \n",
    "    n_sims\n",
    ")\n",
    "\n",
    "# Democratic win probability\n",
    "dem_win_prob = np.mean(dem_totals > 269)  # Need > 269 to win\n",
    "print(f\"Democratic win probability: {dem_win_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of electoral votes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.hist(dem_totals, bins=50, color=PITT_BLUE, edgecolor='white', alpha=0.7)\n",
    "ax.axvline(x=269, color=PITT_GOLD, linewidth=2, linestyle='--', label='Needed to win')\n",
    "ax.set_xlabel('Democratic Electoral Votes')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title(f'Distribution of Democratic EV (n={n_sims} simulations)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Common Shocks (Correlation)\n",
    "\n",
    "The independent model doesn't capture correlations between states. We add common shocks:\n",
    "\n",
    "$$ \\Pr(\\text{State } j \\text{ is Dem}) = \\frac{\\exp(\\alpha_j + \\epsilon)}{\\exp(\\alpha_j + \\epsilon) + 1} $$\n",
    "\n",
    "where $\\epsilon$ is a common $U[-k, k]$ shock and $\\alpha_j$ is a state-level parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_prob(x):\n",
    "    \"\"\"Logistic function: maps R to (0,1).\"\"\"\n",
    "    return np.exp(x) / (np.exp(x) + 1)\n",
    "\n",
    "# Visualize the logistic function\n",
    "x = np.linspace(-10, 10, 200)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(x, exp_prob(x), color=PITT_BLUE, linewidth=2)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('Logistic Function: exp(x)/(exp(x)+1)')\n",
    "ax.axhline(y=0.5, color=PITT_GOLD, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_alpha(p, k):\n",
    "    \"\"\"\n",
    "    Generate alpha parameter from probability p and shock range k.\n",
    "    \n",
    "    Inverts the relationship to get alpha from observed probability.\n",
    "    \"\"\"\n",
    "    if p <= 0.0001:\n",
    "        return -10\n",
    "    elif p >= 0.9999:\n",
    "        return 10\n",
    "    else:\n",
    "        return k + np.log(np.exp(2*p*k) - 1) - np.log(np.exp(2*k) - np.exp(2*k*p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate alpha parameters for each state\n",
    "k_val = 5\n",
    "state_prob['alpha'] = state_prob['dem_prob'].apply(lambda p: gen_alpha(p, k_val))\n",
    "print(state_prob[['dem_prob', 'ev', 'alpha']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_election_with_shock(alpha_list, ev_list, k_param, n_sims):\n",
    "    \"\"\"\n",
    "    Run election simulation with common shock.\n",
    "    \"\"\"\n",
    "    n_states = len(alpha_list)\n",
    "    \n",
    "    # Generate common shock for each simulation\n",
    "    shocks = np.random.uniform(-k_param, k_param, n_sims)\n",
    "    \n",
    "    # Generate random draws for each state in each simulation\n",
    "    rnd = np.random.uniform(0, 1, (n_sims, n_states))\n",
    "    \n",
    "    # Calculate probabilities with shock\n",
    "    alpha_array = np.array(alpha_list)\n",
    "    probs = exp_prob(alpha_array[np.newaxis, :] + shocks[:, np.newaxis])\n",
    "    \n",
    "    # Determine outcomes\n",
    "    dem_wins = rnd < probs\n",
    "    dem_totals = np.sum(dem_wins * np.array(ev_list), axis=1)\n",
    "    \n",
    "    return dem_totals, shocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation with common shocks\n",
    "k_val = 8\n",
    "dem_totals_shock, shocks = run_election_with_shock(\n",
    "    state_prob['alpha'].values,\n",
    "    state_prob['ev'].values,\n",
    "    k_val,\n",
    "    n_sims\n",
    ")\n",
    "\n",
    "dem_win_prob_shock = np.mean(dem_totals_shock > 269)\n",
    "print(f\"Democratic win probability (with shock): {dem_win_prob_shock:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how shock affects outcome\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bin by shock value and calculate mean EV\n",
    "shock_bins = np.linspace(-k_val, k_val, 50)\n",
    "shock_centers = (shock_bins[:-1] + shock_bins[1:]) / 2\n",
    "bin_indices = np.digitize(shocks, shock_bins)\n",
    "\n",
    "mean_ev_by_shock = [np.mean(dem_totals_shock[bin_indices == i]) \n",
    "                    for i in range(1, len(shock_bins))]\n",
    "\n",
    "ax.scatter(shock_centers, mean_ev_by_shock, color=PITT_BLUE, s=30)\n",
    "ax.axhline(y=269, color=PITT_GOLD, linestyle='--', label='Needed to win')\n",
    "ax.set_xlabel('Common Shock')\n",
    "ax.set_ylabel('Mean Democratic EV')\n",
    "ax.set_title('Effect of Common Shock on Election Outcome')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating an Econometric Method\n",
    "\n",
    "Simulations help us understand the **finite-sample properties** of econometric methods.\n",
    "\n",
    "While asymptotic results mean we can use $t$ and $F$ tests for OLS, these may not be appropriate for finite samples with non-normal disturbances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_linear_model(n, beta0=1, beta1=1, sigma_x=1, sigma_u=1):\n",
    "    \"\"\"\n",
    "    Simulate a linear model and return OLS estimate and standard error.\n",
    "    \n",
    "    Uses a very non-normal error distribution (beta distribution).\n",
    "    \"\"\"\n",
    "    # Draw x values\n",
    "    x = np.random.normal(0, sigma_x, n)\n",
    "    \n",
    "    # Draw u from a very non-normal distribution\n",
    "    # R: (rbeta(n, 0.5, 0.5) - 1) * sigma_u * sqrt(8)\n",
    "    u = (np.random.beta(0.5, 0.5, n) - 0.5) * 2 * sigma_u * np.sqrt(8)\n",
    "    \n",
    "    # Generate y\n",
    "    y = beta0 + beta1 * x + u\n",
    "    \n",
    "    # Fit OLS model\n",
    "    X = sm.add_constant(x)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    return {\n",
    "        'estimate': model.params[1],  # beta1 estimate\n",
    "        'std_error': model.bse[1]     # standard error\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test once\n",
    "result = sim_linear_model(50)\n",
    "print(f\"Estimate: {result['estimate']:.4f}\")\n",
    "print(f\"Std Error: {result['std_error']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_sim(func, n_sims=10000, **kwargs):\n",
    "    \"\"\"\n",
    "    Run Monte Carlo simulation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        Function to simulate (must return dict)\n",
    "    n_sims : int\n",
    "        Number of simulations\n",
    "    **kwargs\n",
    "        Arguments to pass to func\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Results from all simulations\n",
    "    \"\"\"\n",
    "    results = [func(**kwargs) for _ in range(n_sims)]\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation with n=25\n",
    "sim_df_25 = monte_carlo_sim(sim_linear_model, n_sims=10000, n=25)\n",
    "print(f\"Mean estimate: {sim_df_25['estimate'].mean():.4f}\")\n",
    "print(f\"Std of estimates: {sim_df_25['estimate'].std():.4f}\")\n",
    "print(f\"Theoretical SE (1/sqrt(n-2)): {1/np.sqrt(23):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of beta_1 estimate\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Histogram of estimates\n",
    "ax.hist(sim_df_25['estimate'], bins=50, density=True, color=PITT_BLUE, \n",
    "        edgecolor='white', alpha=0.7, label='Simulated')\n",
    "\n",
    "# Overlay theoretical normal\n",
    "x = np.linspace(0.4, 1.6, 100)\n",
    "ax.plot(x, stats.norm.pdf(x, 1, 0.2), color=PITT_GOLD, linewidth=3, \n",
    "        label='Normal(1, 0.2)')\n",
    "\n",
    "ax.set_xlabel('Beta_1 Estimate')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Distribution of OLS Estimate (n=25)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-statistic distribution\n",
    "# True beta_1 = 1, so t-stat for H0: beta_1 = 1 is:\n",
    "sim_df_25['t_stat'] = (sim_df_25['estimate'] - 1) / sim_df_25['std_error']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Histogram of t-statistics\n",
    "ax.hist(sim_df_25['t_stat'], bins=50, density=True, color=PITT_BLUE,\n",
    "        edgecolor='white', alpha=0.7, label='Simulated')\n",
    "\n",
    "# Overlay theoretical t-distribution\n",
    "x = np.linspace(-4, 4, 100)\n",
    "ax.plot(x, stats.t.pdf(x, df=23), color=PITT_GOLD, linewidth=3,\n",
    "        label='t(23)')\n",
    "\n",
    "ax.set_xlabel('t-statistic')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('T-statistic Distribution (H0: beta_1 = 1)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type I error rate\n",
    "# Critical value for 95% test with df=23\n",
    "t_crit = stats.t.ppf(0.975, df=23)\n",
    "print(f\"Critical value (97.5%): {t_crit:.4f}\")\n",
    "\n",
    "# Empirical rejection rate\n",
    "type_1_error = np.mean(np.abs(sim_df_25['t_stat']) > t_crit)\n",
    "print(f\"Empirical Type I error rate: {type_1_error:.4f}\")\n",
    "print(f\"Nominal level: 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soccer Scorelines Simulation\n",
    "\n",
    "Using FiveThirtyEight model parameters, we can simulate soccer match outcomes using a Poisson process.\n",
    "\n",
    "A Poisson distribution with parameter $\\lambda$ has:\n",
    "$$ \\Pr(k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} $$\n",
    "\n",
    "For team $i$ playing team $j$, goals scored follow:\n",
    "$$ \\lambda_{ij} = \\exp(\\alpha_i - \\delta_j) $$\n",
    "\n",
    "where $\\alpha_i$ is offense and $\\delta_j$ is defense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FiveThirtyEight team data\n",
    "teams_data = pd.read_csv('538/spi_global_rankings.csv')\n",
    "print(teams_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to Premier League\n",
    "prem_league = teams_data[teams_data['league'] == 'Barclays Premier League'].copy()\n",
    "prem_league = prem_league.set_index('name')\n",
    "\n",
    "# Calculate alpha and delta parameters\n",
    "lmean_def = np.log(prem_league['def'].mean())\n",
    "lmean_off = np.log(prem_league['off'].mean())\n",
    "\n",
    "prem_league['alpha'] = np.log(prem_league['off']) - lmean_def\n",
    "prem_league['delta'] = lmean_off - np.log(prem_league['def'])\n",
    "\n",
    "print(prem_league[['off', 'def', 'alpha', 'delta']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter dictionaries\n",
    "alpha_dict = prem_league['alpha'].to_dict()\n",
    "delta_dict = prem_league['delta'].to_dict()\n",
    "\n",
    "def draw_score(team1, team2):\n",
    "    \"\"\"\n",
    "    Simulate a match between two teams.\n",
    "    \n",
    "    Returns (team1_goals, team2_goals)\n",
    "    \"\"\"\n",
    "    # R: rpois(1, exp(alpha[team1] - delta[team2]))\n",
    "    # Python: np.random.poisson(np.exp(alpha[team1] - delta[team2]))\n",
    "    lambda1 = np.exp(alpha_dict[team1] - delta_dict[team2])\n",
    "    lambda2 = np.exp(alpha_dict[team2] - delta_dict[team1])\n",
    "    \n",
    "    return np.random.poisson(lambda1), np.random.poisson(lambda2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Liverpool vs Manchester City\n",
    "print(\"Liverpool vs Manchester City:\")\n",
    "for i in range(10):\n",
    "    score = draw_score('Liverpool', 'Manchester City')\n",
    "    print(f\"  {score[0]} - {score[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate multiple matches\n",
    "def simulate_matches(team1, team2, n_matches=10000):\n",
    "    \"\"\"Simulate many matches between two teams.\"\"\"\n",
    "    lambda1 = np.exp(alpha_dict[team1] - delta_dict[team2])\n",
    "    lambda2 = np.exp(alpha_dict[team2] - delta_dict[team1])\n",
    "    \n",
    "    goals1 = np.random.poisson(lambda1, n_matches)\n",
    "    goals2 = np.random.poisson(lambda2, n_matches)\n",
    "    \n",
    "    return goals1, goals2\n",
    "\n",
    "# Liverpool vs Arsenal\n",
    "liv_goals, ars_goals = simulate_matches('Liverpool', 'Arsenal', 10000)\n",
    "\n",
    "print(f\"Liverpool vs Arsenal (10,000 simulations):\")\n",
    "print(f\"  Liverpool wins: {np.mean(liv_goals > ars_goals):.3f}\")\n",
    "print(f\"  Draw: {np.mean(liv_goals == ars_goals):.3f}\")\n",
    "print(f\"  Arsenal wins: {np.mean(liv_goals < ars_goals):.3f}\")\n",
    "print(f\"  Average Liverpool goals: {np.mean(liv_goals):.2f}\")\n",
    "print(f\"  Average Arsenal goals: {np.mean(ars_goals):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: R to Python Random Number Mapping\n",
    "\n",
    "| R Function | Python Equivalent |\n",
    "|------------|-------------------|\n",
    "| `runif(n, min, max)` | `np.random.uniform(min, max, n)` |\n",
    "| `rnorm(n, mean, sd)` | `np.random.normal(mean, sd, n)` |\n",
    "| `rpois(n, lambda)` | `np.random.poisson(lambda, n)` |\n",
    "| `rbeta(n, a, b)` | `np.random.beta(a, b, n)` |\n",
    "| `rbinom(n, size, prob)` | `np.random.binomial(size, prob, n)` |\n",
    "| `sample(x, n, replace)` | `np.random.choice(x, n, replace=replace)` |\n",
    "| `ifelse(cond, yes, no)` | `np.where(cond, yes, no)` |\n",
    "| `sapply(vec, fun)` | `[fun(x) for x in vec]` or `np.vectorize(fun)(vec)` |\n",
    "\n",
    "**Performance tip:** In Python, vectorized operations with NumPy are much faster than loops. Always try to generate all random numbers at once rather than in a loop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
