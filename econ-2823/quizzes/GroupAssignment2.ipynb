{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "based-insight",
   "metadata": {},
   "source": [
    "# Group Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-workstation",
   "metadata": {},
   "source": [
    "## Main Assignment\n",
    "For Friday I would like you to prepare a visualization comparing the accuracy of confidence intervals generated by:\n",
    "* A bootstrap over the data\n",
    "*  Standard inference (using the Delta-method for transformations)\n",
    "## Specifics\n",
    "For this exercise I would like you to look at GLM estimates for a Poisson outcome with a mean given by:\n",
    "$$\\lambda_i=\\text{exp}\\left\\{\\beta_0+\\beta_1\\delta_{i,1}+\\beta_2x_{i,2}\\right\\}$$\n",
    "\n",
    "where:\n",
    "* $\\delta_{i,1}$ is a dummy variable taking value 1 with 60 percent chance, 0 with a 40 percent chance\n",
    "    * Think of this as a factor characteristic\n",
    "* $x_{i,2}$ is a draw from a chi-squared distribution, however:\n",
    "    * If $\\delta_{i,1}$  is one, it is  drawn from a distribution with 4 degrees of freedom\n",
    "    * If $\\delta_{i,1}$  is zero, it is  drawn from a distribution with 2 degrees of freedom\n",
    "    * Think of this as an economic measure that is correlated with the factor.\n",
    "    \n",
    "We will set the true values of the parameters as:\n",
    "* $\\beta _0=-1$\n",
    "* $\\beta_1=-1$\n",
    "* $\\beta_2=\\tfrac{1}{2}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-nylon",
   "metadata": {},
   "source": [
    "Load in libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(boot)\n",
    "library(MASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-jefferson",
   "metadata": {},
   "source": [
    "Function to create a new draw of the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw.data <- function(N, beta=c(-1,-1,1/2)) {\n",
    "    x1 <- ifelse(runif(N)<0.4,0,1) # Draw 0 with 40% chance, 1 otherwise\n",
    "    x2.0 <- rchisq(N,df=2) # Draw a Chi-squared 2\n",
    "    x2.1 <- rchisq(N,df=4) # Draw a Chi-squared 4\n",
    "    x2 <- ifelse(x1==1,x2.1,x2.0) \n",
    "    const <- rep(1,N)\n",
    "    Xmat <- cbind(const,delta1=x1,x2=x2) # Make the data, [column of ones, delta1, x2]\n",
    "    eta <- Xmat%*% beta\n",
    "    lambda <- exp(eta)\n",
    "    # Draw a Poisson from the releveant distribution\n",
    "    generateY <- function(lambda.i) rpois(1,lambda=lambda.i)\n",
    "    y <- sapply(lambda,generateY)\n",
    "    data.frame(cbind(y=y,Xmat[,2:3]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-prefix",
   "metadata": {},
   "source": [
    "For the transformation we're trying to estimate the probability that a poisson is 0 or 1. For a mean of $\\lambda$ this probability is given by:\n",
    "$$h(\\lambda)=\\Pr\\left\\{y<2\\right\\}=\\Pr\\left\\{y=0\\right\\}+\\Pr\\left\\{y=1\\right\\}= e^{-\\lambda}+e^{-\\lambda}\\lambda=e^{-\\lambda}(1+\\lambda)$$\n",
    "The derivative with respect to $\\lambda_i$ is therefore:\n",
    "$$\\frac{\\partial h(\\lambda)}{\\partial \\lambda}= -e^{-\\lambda}(1+\\lambda) +e^{-\\lambda}=e^{-\\lambda}\\left( 1-1-\\lambda \\right) =-\\lambda  e^{-\\lambda}$$\n",
    "\n",
    "But we know that $\\lambda(\\beta_0,\\beta_1,\\beta_2)=\\exp\\left(\\beta_0+\\beta_1+4\\cdot\\beta_2\\right)$ and we really want the partial derivatives with respect to each of the parameters. But this means we're just using the chain rule where:\n",
    "$$\\frac{\\partial h( \\lambda(\\beta_0,\\beta_1,\\beta_2) )}{\\partial \\beta_0}=\\frac{\\partial h(\\lambda)}{\\partial \\lambda} \\frac{\\partial \\lambda(\\beta_0,\\beta_1,\\beta_2)}{\\partial \\beta_0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-token",
   "metadata": {},
   "source": [
    "But we know that \n",
    "$$\\frac{\\partial \\lambda(\\beta_0,\\beta_1,\\beta_2)}{\\partial \\beta_0}=\\lambda(\\beta_0,\\beta_1,\\beta_2)$$\n",
    "$$\\frac{\\partial \\lambda(\\beta_0,\\beta_1,\\beta_2)}{\\partial \\beta_1}=\\delta_1\\lambda(\\beta_0,\\beta_1,\\beta_2)$$\n",
    "$$\\frac{\\partial \\lambda(\\beta_0,\\beta_1,\\beta_2)}{\\partial \\beta_2}=x_2\\lambda(\\beta_0,\\beta_1,\\beta_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-packing",
   "metadata": {},
   "source": [
    "Make the function for the probability of being 0 or 1 with the argument being the coefficient vector: $(\\hat{\\beta}_0,\\hat{\\beta}_1,\\hat{\\beta}_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.0.1 <- function(beta.hat) {\n",
    "    lambda <- exp( beta.hat[1]+beta.hat[2]+4*beta.hat[3])\n",
    "    g <- unname( (1+lambda)*exp(-lambda) )\n",
    "    return( c(\"Prob.0.1\"=g))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-shannon",
   "metadata": {},
   "source": [
    "Generate the Delta-Method confidence interval with the arguments being the estimates  $\\hat{\\beta}=(\\hat{\\beta}_0,\\hat{\\beta}_1,\\hat{\\beta}_2)$, the variance-covariance matrix estimate $\\hat{\\Sigma}$, and the point we want to assess the model at $x=(x_1,x_2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta.Method.pois <- function(model,xAt=c(1,4),confAt=c(0.8,0.9,0.95)){\n",
    "    Sigma <- vcov(model)\n",
    "    beta.hat <- coef(model)\n",
    "    # Here I use the above to just write the formula directly.\n",
    "    g.est <- prob.0.1(beta.hat)\n",
    "    lambda <- exp(  t(c(1,xAt) )%*%beta.hat)[1,1]\n",
    "    dH <-  -lambda* exp(-lambda)\n",
    "    dG <- dH*lambda*c( 1 , xAt )\n",
    "    se <- sqrt(t(dG) %*% Sigma %*% dG)[1,1] \n",
    "    critVals <- qnorm(1-(1-confAt)/2)\n",
    "    # Return a matrix across the confidence intervals for upper and lower\n",
    "    return(cbind(g.lower=g.est-critVals*se,g.upper=g.est+critVals*se))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-steam",
   "metadata": {},
   "source": [
    "Generate the standard errors from the expected score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard.analysis <- function(data){\n",
    "    est.model.glm <- glm(y~delta1+x2,data=data,family=\"poisson\")\n",
    "    beta.hat <- unname(coef(est.model.glm))\n",
    "    c80 <- confint(profile(est.model.glm),level=0.80)\n",
    "    c90 <- confint(profile(est.model.glm),level=0.90)\n",
    "    c95 <- confint(profile(est.model.glm),level=0.95)\n",
    "    g <- Delta.Method.pois( est.model.glm , xAt=c(1,4) )\n",
    "    g.hat <- prob.0.1(beta.hat)\n",
    "    outMat <- rbind(   # join these rows together\n",
    "        c(id=1,estimate=beta.hat[1],conf.80.lower=c80[1,1],conf.80.upper=c80[1,2],conf.90.lower=c90[1,1],conf.90.upper=c90[1,2],conf.95.lower=c95[1,1],conf.95.upper=c95[1,2]),\n",
    "        c(id=2,estimate=beta.hat[2],conf.80.lower=c80[2,1],conf.80.upper=c80[2,2],conf.90.lower=c90[2,1],conf.90.upper=c90[2,2],conf.95.lower=c95[2,1],conf.95.upper=c95[2,2]),\n",
    "        c(id=3,estimate=beta.hat[3],conf.80.lower=c80[3,1],conf.80.upper=c80[3,2],conf.90.lower=c90[3,1],conf.90.upper=c90[3,2],conf.95.lower=c95[3,1],conf.95.upper=c95[3,2]),\n",
    "        c(id=4,estimate=g.hat      ,conf.80.lower=  g[1,1],conf.80.upper=  g[1,2],conf.90.lower=  g[2,1],conf.90.upper=  g[2,2],conf.95.lower=  g[3,1],conf.95.upper=  g[3,2])\n",
    "        )\n",
    "    return(outMat)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-expression",
   "metadata": {},
   "source": [
    "# Bootstraps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-reducing",
   "metadata": {},
   "source": [
    "Function to return bootstraps over the three coefficients, and the transformed probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois.bs <- function(formula, data, indices) {\n",
    "  d <- data[indices,]\n",
    "  pois.fit <- glm(formula, data=d,family=\"poisson\")\n",
    "  # Return the coefficients of the glm model and the Prob of a 0 or 1\n",
    "  return( c( coef(pois.fit), prob.0.1(coef(pois.fit))[1] )  ) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap.analysis <- function(data){\n",
    "    # Estimate the model\n",
    "    est.model.glm <- glm(y~delta1+x2,data=data,family=\"poisson\")\n",
    "    beta.hat <- unname(coef(est.model.glm))\n",
    "    # figure out the transformation\n",
    "    g.hat <- prob.0.1(beta.hat)\n",
    "    # Bootstrap the drawn data 250 times\n",
    "    bs.result <- boot(data=data, statistic=pois.bs,R=250, formula=y~ delta1+x2)\n",
    "    # assemble confidence intervals from the data using a normal fit\n",
    "    b0 <- boot.ci(bs.result,conf=c(0.8,0.9,0.95),type=\"norm\",index=1)$normal\n",
    "    b1 <- boot.ci(bs.result,conf=c(0.8,0.9,0.95),type=\"norm\",index=2)$normal\n",
    "    b2 <- boot.ci(bs.result,conf=c(0.8,0.9,0.95),type=\"norm\",index=3)$normal\n",
    "    g <- boot.ci(bs.result,conf=c(0.8,0.9,0.95),type=\"norm\",index=4)$normal\n",
    "    # Output the data in an organized way!\n",
    "    outMat <- rbind( # join these rows together\n",
    "            c(id=1,estimate=beta.hat[1],conf.80.lower=b0[1,2],conf.80.upper=b0[1,3],conf.90.lower=b0[2,2],conf.90.upper=b0[2,3],conf.95.lower=b0[3,2],conf.95.upper=b0[3,3]),\n",
    "            c(id=2,estimate=beta.hat[2],conf.80.lower=b1[1,2],conf.80.upper=b1[1,3],conf.90.lower=b1[2,2],conf.90.upper=b1[2,3],conf.95.lower=b1[3,2],conf.95.upper=b1[3,3]),\n",
    "            c(id=3,estimate=beta.hat[3],conf.80.lower=b2[1,2],conf.80.upper=b2[1,3],conf.90.lower=b2[2,2],conf.90.upper=b2[2,3],conf.95.lower=b2[3,2],conf.95.upper=b2[3,3]),\n",
    "            c(id=4,estimate=g.hat      ,conf.80.lower= g[1,2],conf.80.upper= g[1,3],conf.90.lower= g[2,2],conf.90.upper= g[2,3],conf.95.lower= g[3,2],conf.95.upper= g[3,3])\n",
    "            )\n",
    "    return(outMat)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-velvet",
   "metadata": {},
   "source": [
    "Overall simulation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "conductSims <- function(N,Nsim=10000) {\n",
    "    # initialize the matrices\n",
    "    std.matrix <-matrix(0,nrow=Nsim*4,ncol=8)\n",
    "    bs.matrix <- matrix(0,nrow=Nsim*4,ncol=8)\n",
    "    # set the column names\n",
    "    colnames(std.matrix) <- c('id','estimate','conf.80.lower','conf.80.upper','conf.90.lower','conf.90.upper','conf.95.lower','conf.95.upper')\n",
    "    colnames(bs.matrix) <-  c('id','estimate','conf.80.lower','conf.80.upper','conf.90.lower','conf.90.upper','conf.95.lower','conf.95.upper')\n",
    "    for (i in 1:Nsim){\n",
    "        i.lower <- 4*(i-1)+1 # Get indices in bigger matrix for this simulation as multiple of 4 (1 for i=1, 5 for i=2, etc)\n",
    "        i.upper <- i.lower+3 # Upper index is i.lower+3 (4 for i=1, 8 for i=2, etc.)\n",
    "        data <- draw.data(N) # draw a new set of data\n",
    "        std.matrix[i.lower:i.upper, ] <- standard.analysis(data)  # run the standard analysis on the data\n",
    "        bs.matrix[i.lower:i.upper, ]  <- bootstrap.analysis(data) # run the bootstrap analysis on the data\n",
    "        ## If running in R studio you can uncomment this to get a post every 100 repetitions.\n",
    "        #if (i%%100 ==0){\n",
    "        #    print(paste0(\"Completed \",toString(i),\" repetitions.\"))\n",
    "        #}\n",
    "    }\n",
    "    # Now convert the two matrices into data frames\n",
    "    df.std <- data.frame(std.matrix)\n",
    "    df.std[\"type\"] <- \"standard\"\n",
    "    df.bs <- data.frame(bs.matrix)\n",
    "    df.bs[\"type\"] <- \"bs\"\n",
    "    # and append them together (where we can subset on type, etc later)\n",
    "    df <- rbind(df.bs,df.std)\n",
    "    # Now its a dataframe can include strings! Here is the ID to metric link\n",
    "    key <- data.frame(id=c(1:4), metric=c(\"beta0\",\"beta1\",\"beta2\",\"Prob.0.1\"))\n",
    "    # create a metric column\n",
    "    df['metric'] <- key[ match(df[['id']], key[['id']] ) , 'metric']\n",
    "    # Output the dataframe in the order (metric, type, data columns 2:8)\n",
    "    return(df[ ,c(10,9,2:8)])\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "compliant-hopkins",
   "metadata": {},
   "source": [
    "compare.ci.50 <- conductSims(50,Nsim=10000)\n",
    "save(compare.ci.50,file='comp50.rdata')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dutch-shock",
   "metadata": {},
   "source": [
    "compare.ci.100 <- conductSims(100,Nsim=10000)\n",
    "save(compare.ci.100,file='comp100.rdata')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ready-lotus",
   "metadata": {},
   "source": [
    "compare.ci.200 <- conductSims(200,Nsim=10000)\n",
    "save(compare.ci.200,file='comp200.rdata')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "daily-connecticut",
   "metadata": {},
   "source": [
    "compare.ci.400 <- conductSims(400,Nsim=10000)\n",
    "save(compare.ci.400,file='comp400.rdata')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "innovative-charles",
   "metadata": {},
   "source": [
    "compare.ci.800 <- conductSims(800,Nsim=10000)\n",
    "save(compare.ci.800,file='comp800.rdata')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "three-impossible",
   "metadata": {},
   "source": [
    "compare.ci.1600 <- conductSims(1600,Nsim=10000)\n",
    "save(compare.ci.100,file='comp1600.rdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-cleaners",
   "metadata": {},
   "source": [
    "Load in from saved versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "load(file='comp50.rdata')\n",
    "load(file='comp100.rdata')\n",
    "load(file='comp200.rdata')\n",
    "load(file='comp400.rdata')\n",
    "load(file='comp800.rdata')\n",
    "load(file='comp1600.rdata')\n",
    "load(file='comp3200.rdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.ci.50[\"N\"]<- 50\n",
    "compare.ci.100[\"N\"]<- 100\n",
    "compare.ci.200[\"N\"]<- 200\n",
    "compare.ci.400[\"N\"]<- 400\n",
    "compare.ci.800[\"N\"]<- 800\n",
    "compare.ci.1600[\"N\"]<- 1600\n",
    "compare.ci.3200[\"N\"]<- 3200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.data<- rbind(compare.ci.50,compare.ci.100,compare.ci.200,compare.ci.400,compare.ci.800,compare.ci.1600,compare.ci.3200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors\n",
    "Pitt.Blue<- \"#003594\"\n",
    "Pitt.Gold<-\"#FFB81C\"\n",
    "Pitt.DGray <- \"#75787B\"\n",
    "Pitt.Gray <- \"#97999B\"\n",
    "Pitt.LGray <- \"#C8C9C7\"\n",
    "# ggplot preferences\n",
    "library(\"ggplot2\")\n",
    "library(\"repr\")\n",
    "options(repr.plot.width=10, repr.plot.height=10/1.68)\n",
    "Pitt.Theme<-theme( panel.background = element_rect(fill = \"white\", size = 0.5, linetype = \"solid\"),\n",
    "  panel.grid.major = element_line(size = 0.5, linetype = 'solid', colour =Pitt.Gray), \n",
    "  panel.grid.minor = element_line(size = 0.25, linetype = 'solid', colour = \"white\")\n",
    "  )\n",
    "base<- ggplot() +aes()+ Pitt.Theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=subset(sim.data,metric==\"Prob.0.1\" & type==\"bs\" & N==3200), aes(x=estimate))+Pitt.Theme+\n",
    "geom_histogram(binwidth=0.001,color=Pitt.Blue,fill=Pitt.Gold, size=2,aes(y=..density..))+xlab(\"Outcome Prob\")+ylab(\"Density\")+\n",
    "stat_function(fun = dnorm, args = list(mean = 1, sd = 0.2425328978796))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nlist=c(50,100,200,400,800,1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricList <- c('beta0','beta1','beta2','Prob.0.1')\n",
    "actual.sample <- data.frame()\n",
    "for (m in metricList){ \n",
    "    SampleDist <- matrix(0, ncol=7,nrow=length(Nlist))\n",
    "    for (ii in 1:length(Nlist)) {\n",
    "        Nn <- Nlist[ii]\n",
    "       SampleDist[ii , ] <- c(N=Nn,quantile(subset(sim.data,metric==m & type==\"bs\" & N==Nn)$estimate,c(0.025,0.05,0.1,0.9,0.95,0.975)))\n",
    "    }\n",
    "    colnames(SampleDist) <- c(\"N\",'q.025','q.05','q.1','q.9','q.95','q.975')\n",
    "    df0 <- data.frame(SampleDist)\n",
    "    df0['metric'] <- m\n",
    "    actual.sample <- rbind(actual.sample,df0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ActualInt <- function(stat,N,lower,upper){\n",
    "    quantile(subset(sim.data,metric==stat & type==\"bs\" & N==N)$estimate,c(lower,upper) )\n",
    "}\n",
    "library(stats)\n",
    "CoverageInt <- function(stat,N,lower,upper){\n",
    "    Fn <- ecdf(subset(sim.data,metric==stat & type==\"bs\" & N==N)$estimate)\n",
    "    Fn(upper)-Fn(lower)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-consortium",
   "metadata": {},
   "source": [
    "# Parameter: $\\beta_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "Type1.beta0 <- subset( sim.data,metric==\"beta0\" )\n",
    "for (conf in c(80,90,95)) {\n",
    "    contStr <- toString(conf)\n",
    "    contStr.up <- paste0(\"conf.\",toString(conf),\".upper\")\n",
    "    contStr.low <-  paste0(\"conf.\",toString(conf),\".lower\")\n",
    "    namecol <- paste0(\"tI.\",toString(conf))\n",
    "    Type1.beta0[namecol] <- ifelse( -1>=Type1.beta0[,contStr.low] & -1<=Type1.beta0[,contStr.up] ,TRUE,FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "Error.beta0 <- data.frame(matrix( 0, ncol = 4, nrow = 12))\n",
    "names(Error.beta0) <- c(\"N\",'tI.80','tI.90','tI.95')\n",
    "Error.beta0[\"type\"] <- \"empty\"\n",
    "ii <- 0\n",
    "for (typei in c(\"bs\",\"standard\")) {\n",
    "    for (Nj in Nlist){\n",
    "        ii <- ii+1\n",
    "        Error.beta0[ii, c(\"N\",'tI.80','tI.90','tI.95','type')] <- list(Nj, \n",
    "                 round(100*(mean( subset(Type1.beta0, type==typei & N==Nj)$tI.80 )),4) , \n",
    "                 round(100*(mean( subset(Type1.beta0, type==typei & N==Nj)$tI.90 )),4) ,\n",
    "                 round(100*(mean( subset(Type1.beta0, type==typei & N==Nj)$tI.95 )),4) ,typei)             \n",
    "    }\n",
    "}\n",
    "Error.beta0['metric'] <- 'beta0'\n",
    "Error.beta0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-monroe",
   "metadata": {},
   "source": [
    "# Parameter: $\\beta_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "Type1.beta1 <- subset( sim.data,metric==\"beta1\" )\n",
    "for (conf in c(80,90,95)) {\n",
    "    contStr <- toString(conf)\n",
    "    contStr.up <- paste0(\"conf.\",toString(conf),\".upper\")\n",
    "    contStr.low <-  paste0(\"conf.\",toString(conf),\".lower\")\n",
    "    namecol <- paste0(\"tI.\",toString(conf))\n",
    "    Type1.beta1[namecol] <- ifelse( -1>=Type1.beta1[,contStr.low] & -1<=Type1.beta1[,contStr.up] ,TRUE,FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "Error.beta1 <- data.frame(matrix( 0, ncol = 4, nrow = 12))\n",
    "names(Error.beta1) <- c(\"N\",'tI.80','tI.90','tI.95')\n",
    "Error.beta1[\"type\"] <- \"empty\"\n",
    "ii <- 0\n",
    "for (typei in c(\"bs\",\"standard\")) {\n",
    "    for (Nj in Nlist){\n",
    "        ii <- ii+1\n",
    "        Error.beta1[ii, c(\"N\",'tI.80','tI.90','tI.95','type')] <- list(Nj, \n",
    "                 round(100*(mean( subset(Type1.beta1, type==typei & N==Nj)$tI.80 )),4) , \n",
    "                 round(100*(mean( subset(Type1.beta1, type==typei & N==Nj)$tI.90 )),4) ,\n",
    "                 round(100*(mean( subset(Type1.beta1, type==typei & N==Nj)$tI.95 )),4) ,typei)             \n",
    "    }\n",
    "}\n",
    "Error.beta1['metric'] <- 'beta1'\n",
    "Error.beta1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-provision",
   "metadata": {},
   "source": [
    "# Parameter: $\\beta_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "Type1.beta2 <- subset( sim.data,metric==\"beta2\" )\n",
    "for (conf in c(80,90,95)) {\n",
    "    contStr <- toString(conf)\n",
    "    contStr.up <- paste0(\"conf.\",toString(conf),\".upper\")\n",
    "    contStr.low <-  paste0(\"conf.\",toString(conf),\".lower\")\n",
    "    namecol <- paste0(\"tI.\",toString(conf))\n",
    "    Type1.beta2[namecol] <- ifelse( 1/2 >=Type1.beta2[ ,contStr.low] & 1/2 <=Type1.beta2[ ,contStr.up] ,TRUE,FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "Error.beta2 <- data.frame(matrix( 0, ncol = 4, nrow = 12))\n",
    "names(Error.beta2) <- c(\"N\",'tI.80','tI.90','tI.95')\n",
    "Error.beta2[\"type\"] <- \"empty\"\n",
    "ii <- 0\n",
    "for (typei in c(\"bs\",\"standard\") )  {\n",
    "    for (Nj in Nlist){\n",
    "        ii <- ii+1\n",
    "        Error.beta2[ii, c(\"N\",'tI.80','tI.90','tI.95','type')] <- list(Nj, \n",
    "                 round(100*(mean( subset(Type1.beta2, type==typei & N==Nj)$tI.80 )),4) , \n",
    "                 round(100*(mean( subset(Type1.beta2, type==typei & N==Nj)$tI.90 )),4) ,\n",
    "                 round(100*(mean( subset(Type1.beta2, type==typei & N==Nj)$tI.95 )),4) ,typei)             \n",
    "    }\n",
    "}\n",
    "Error.beta2['metric'] <- 'beta2'\n",
    "Error.beta2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-block",
   "metadata": {},
   "source": [
    "# Parameter: $\\Pr\\left\\{X\\leq1\\right\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "Type1.prob.0.1 <- subset( sim.data,metric==\"Prob.0.1\" )\n",
    "true.p <- prob.0.1(c(-1,-1,1/2))\n",
    "for (conf in c(80,90,95)) {\n",
    "    contStr <- toString(conf)\n",
    "    contStr.up <- paste0(\"conf.\",toString(conf),\".upper\")\n",
    "    contStr.low <-  paste0(\"conf.\",toString(conf),\".lower\")\n",
    "    namecol <- paste0(\"tI.\",toString(conf))\n",
    "    Type1.prob.0.1[namecol] <- ifelse( true.p>=Type1.prob.0.1[,contStr.low] & true.p<=Type1.prob.0.1[,contStr.up] ,TRUE,FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "Error.prob.0.1 <- data.frame(matrix( 0, ncol = 4, nrow = 12))\n",
    "names(Error.prob.0.1) <- c(\"N\",'tI.80','tI.90','tI.95')\n",
    "Error.prob.0.1[\"type\"] <- \"empty\"\n",
    "ii <- 0\n",
    "for (typei in c(\"bs\",\"standard\")) {\n",
    "    for (Nj in Nlist){\n",
    "        ii <- ii+1\n",
    "        Error.prob.0.1[ii, c(\"N\",'tI.80','tI.90','tI.95','type')] <- list(Nj, \n",
    "                 round(100*(mean( subset(Type1.prob.0.1, type==typei & N==Nj)$tI.80 )),4) , \n",
    "                 round(100*(mean( subset(Type1.prob.0.1, type==typei & N==Nj)$tI.90 )),4) ,\n",
    "                 round(100*(mean( subset(Type1.prob.0.1, type==typei & N==Nj)$tI.95 )),4) ,typei)             \n",
    "    }\n",
    "}\n",
    "Error.prob.0.1['metric'] <- 'prob.0.1'\n",
    "Error.prob.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-helen",
   "metadata": {},
   "source": [
    "## Bring the results together|\n",
    "Put results into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults <- rbind(Error.beta0,Error.beta1,Error.beta2,Error.prob.0.1)\n",
    "allResults$tI.80ratio <-100/(100-allResults$tI.80)\n",
    "allResults$tI.90ratio <-(100)/(100-allResults$tI.90)\n",
    "allResults$tI.95ratio <-(100)/(100-allResults$tI.95)\n",
    "subset(allResults,metric==\"beta0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-portland",
   "metadata": {},
   "source": [
    "$\\beta_0$ 90 percent, where I present this as an inverse odds ratio (out of how many draws are you expected to falsely reject the null!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=subset(allResults,metric==\"beta0\"), aes(x=N, y=tI.90ratio, color=type)  )+geom_point(size=5) +\n",
    "theme(legend.position='top')+ Pitt.Theme + \n",
    "geom_hline(aes(yintercept=10,color=\"Nominal\"),size=1) +\n",
    "xlab(\"N\")+ylab(\"Type I - inverse odds ratio \") +scale_x_continuous(trans='log10') +\n",
    "scale_color_manual(name='',values=c(\"bs\"= Pitt.Blue,\"standard\"= Pitt.Gold,\"Nominal\"=\"#DC582A\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-hormone",
   "metadata": {},
   "source": [
    "$\\beta_0$ 95 percent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=subset(allResults,metric==\"beta0\"), aes(x=N, y=tI.95ratio, color=type)  )+geom_point(size=5) +\n",
    "theme(legend.position='top')+ Pitt.Theme + \n",
    "geom_hline(aes(yintercept=20,color=\"Nominal\"),size=1) +\n",
    "xlab(\"N\")+ylab(\"Type I - inverse odds ratio\") +scale_x_continuous(trans='log10') +\n",
    "scale_color_manual(name='',values=c(\"bs\"= Pitt.Blue,\"standard\"= Pitt.Gold,\"Nominal\"=\"#DC582A\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-telephone",
   "metadata": {},
   "source": [
    "$\\beta_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=subset(allResults,metric==\"beta1\"), aes(x=N, y=tI.95ratio, color=type)  )+geom_point(size=5) +\n",
    "theme(legend.position='top')+ Pitt.Theme + \n",
    "geom_hline(aes(yintercept=20,color=\"Nominal\"),size=1) +\n",
    "xlab(\"N\")+ylab(\"Type I - inverse odds ratio\") +scale_x_continuous(trans='log10') +\n",
    "scale_color_manual(name='',values=c(\"bs\"= Pitt.Blue,\"standard\"= Pitt.Gold,\"Nominal\"=\"#DC582A\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-writer",
   "metadata": {},
   "source": [
    "$\\beta_2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=subset(allResults,metric==\"beta2\"), aes(x=N, y=tI.95ratio, color=type)  )+geom_point(size=5) +\n",
    "theme(legend.position='top')+ Pitt.Theme + \n",
    "geom_hline(aes(yintercept=20,color=\"Nominal\"),size=1) +\n",
    "xlab(\"N\")+ylab(\"Type I - inverse odds ratio\") +scale_x_continuous(trans='log10') +\n",
    "scale_color_manual(name='',values=c(\"bs\"= Pitt.Blue,\"standard\"= Pitt.Gold,\"Nominal\"=\"#DC582A\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-signature",
   "metadata": {},
   "source": [
    "Draw the graph for the probability comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=subset(allResults,metric==\"prob.0.1\"), aes(x=N, y=tI.95ratio, color=type)  )+geom_point(size=5) +\n",
    "theme(legend.position='top')+ Pitt.Theme + \n",
    "geom_hline(aes(yintercept=20,color=\"Nominal\"),size=1) +\n",
    "xlab(\"N\")+ylab(\"Type I - inverse odds ratio\") +scale_x_continuous(trans='log10') +\n",
    "scale_color_manual(name='',values=c(\"bs\"= Pitt.Blue,\"standard\"= Pitt.Gold,\"Nominal\"=\"#DC582A\") )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
